{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from thop import profile\n",
    "from thop import clever_format\n",
    "torch.backends.cudnn.enabled = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "传统卷积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class double_conv2d_bn(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, strides=1, padding=1):\n",
    "        super(double_conv2d_bn, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=strides, padding=padding, bias=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, stride=strides, padding=padding, bias=True)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        return out\n",
    "\n",
    "class deconv2d_bn(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=2, strides=2):\n",
    "        super(deconv2d_bn, self).__init__()\n",
    "        self.conv1 = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=kernel_size, stride=strides, bias=True)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "深度可分离卷积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class depthwise_separable_conv(nn.Module):\n",
    "    \"\"\"MobileNet V1风格的深度可分离卷积块\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "        super().__init__()\n",
    "        # 深度卷积\n",
    "        self.depthwise = nn.Conv2d(\n",
    "            in_channels,\n",
    "            in_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            groups=in_channels,  # 关键参数：分组数=输入通道数\n",
    "            bias=False\n",
    "        )\n",
    "        # 逐点卷积\n",
    "        self.pointwise = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.depthwise(x)))  # 深度卷积+BN+ReLU\n",
    "        x = F.relu(self.bn2(self.pointwise(x)))  # 逐点卷积+BN+ReLU\n",
    "        return x\n",
    "\n",
    "class double_conv2d_bn(nn.Module):\n",
    "    \"\"\"双深度可分离卷积块（替换原始双标准卷积）\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, strides=1, padding=1):\n",
    "        super().__init__()\n",
    "        # 第一个深度可分离卷积\n",
    "        self.conv1 = depthwise_separable_conv(\n",
    "            in_channels, \n",
    "            out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=strides,\n",
    "            padding=padding\n",
    "        )\n",
    "        # 第二个深度可分离卷积\n",
    "        self.conv2 = depthwise_separable_conv(\n",
    "            out_channels,\n",
    "            out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=strides,\n",
    "            padding=padding\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "\n",
    "class deconv2d_bn(nn.Module):\n",
    "    \"\"\"反卷积块（保持原结构不变）\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=2, strides=2):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.ConvTranspose2d(\n",
    "            in_channels, out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=strides, bias=True\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.relu(self.bn1(self.conv1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出形状: torch.Size([10, 3, 300, 300])\n"
     ]
    }
   ],
   "source": [
    "class UnetS1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UnetS1, self).__init__()\n",
    "        # self.mycustomlayer = MyCustomLayer()\n",
    "        self.layer1_conv = double_conv2d_bn(1, 12)\n",
    "        self.pointwise = nn.Conv2d(\n",
    "            2,\n",
    "            12,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=False\n",
    "        )\n",
    "        self.layer2_conv = double_conv2d_bn(12, 24)\n",
    "        self.layer3_conv = double_conv2d_bn(24, 12)\n",
    "        # self.layer3_conv = double_conv2d_bn(12, 12)\n",
    "        self.layer4_conv = nn.Conv2d(12,3,kernel_size=3,\n",
    "                                     stride=1,padding=1,bias=True)\n",
    "        \n",
    "        self.deconv1 = deconv2d_bn(24, 12)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):      \n",
    "        conv1_2 = self.layer1_conv(x)\n",
    "        pool1 = F.max_pool2d(conv1_2, 2)\n",
    "        \n",
    "        conv2 = self.layer2_conv(pool1)\n",
    "        \n",
    "        convt1 = self.deconv1(conv2)\n",
    "        concat1 = torch.cat([convt1, conv1_2], dim=1)\n",
    "        conv3 = self.layer3_conv(concat1)\n",
    "        \n",
    "        conv4 = self.layer4_conv(conv3)\n",
    "        outp = self.sigmoid(conv4)\n",
    "        return outp\n",
    "model = UnetS1()\n",
    "inp = torch.rand(10, 1, 300, 300)\n",
    "outp = model(inp)\n",
    "print(\"输出形状:\", outp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出形状: torch.Size([10, 3, 300, 300])\n"
     ]
    }
   ],
   "source": [
    "class UnetS2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UnetS2, self).__init__()\n",
    "        # self.mycustomlayer = MyCustomLayer()\n",
    "        self.layer1_conv = double_conv2d_bn(1, 12)\n",
    "        self.pointwise = nn.Conv2d(\n",
    "            1,\n",
    "            12,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=False\n",
    "        )\n",
    "        self.layer2_conv = double_conv2d_bn(12, 24)\n",
    "        self.layer3_conv = double_conv2d_bn(24, 48)\n",
    "        \n",
    "        self.layer4_conv = double_conv2d_bn(48, 24)\n",
    "        self.layer5_conv = double_conv2d_bn(24, 12)\n",
    "        self.layer6_conv = nn.Conv2d(12,3,kernel_size=3,\n",
    "                                     stride=1,padding=1,bias=True)\n",
    "        \n",
    "        self.deconv1 = deconv2d_bn(48, 24)\n",
    "        self.deconv2 = deconv2d_bn(24, 12)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        conv1_2 = self.layer1_conv(x)\n",
    "        pool1 = F.max_pool2d(conv1_2, 2)\n",
    "        \n",
    "        conv2 = self.layer2_conv(pool1)\n",
    "        pool2 = F.max_pool2d(conv2, 2)\n",
    "        \n",
    "        conv3 = self.layer3_conv(pool2)\n",
    "\n",
    "        convt1 = self.deconv1(conv3)\n",
    "        concat1 = torch.cat([convt1, conv2], dim=1)\n",
    "        conv4 = self.layer4_conv(concat1)\n",
    "        \n",
    "        convt2 = self.deconv2(conv4)\n",
    "        concat2 = torch.cat([convt2, conv1_2], dim=1)\n",
    "        conv5 = self.layer5_conv(concat2)\n",
    "\n",
    "        conv6 = self.layer6_conv(conv5)\n",
    "        outp = self.sigmoid(conv6)\n",
    "        return outp\n",
    "model = UnetS2()\n",
    "inp = torch.rand(10, 1, 300, 300)\n",
    "outp = model(inp)\n",
    "print(\"输出形状:\", outp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出形状: torch.Size([10, 3, 300, 300])\n"
     ]
    }
   ],
   "source": [
    "class UnetS3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UnetS3, self).__init__()\n",
    "        # self.mycustomlayer = MyCustomLayer()\n",
    "        self.layer1_conv = double_conv2d_bn(1, 12)\n",
    "        self.pointwise = nn.Conv2d(\n",
    "            1,\n",
    "            12,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=False\n",
    "        )\n",
    "        self.layer2_conv = double_conv2d_bn(12, 24)\n",
    "        self.layer3_conv = double_conv2d_bn(24, 48)\n",
    "        self.layer4_conv = double_conv2d_bn(48, 96)\n",
    "        self.layer5_conv = double_conv2d_bn(96, 48)\n",
    "        self.layer6_conv = double_conv2d_bn(48, 24)\n",
    "        self.layer7_conv = double_conv2d_bn(24, 12)\n",
    "        \n",
    "        self.layer8_conv = nn.Conv2d(12,3,kernel_size=3,\n",
    "                                     stride=1,padding=1,bias=True)\n",
    "        \n",
    "        self.deconv1 = deconv2d_bn(96, 48)\n",
    "        self.deconv2 = deconv2d_bn(48, 24)\n",
    "        self.deconv3 = deconv2d_bn(24, 12)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        conv1_2 = self.layer1_conv(x)\n",
    "        pool1 = F.max_pool2d(conv1_2, 2)\n",
    "        \n",
    "        conv2 = self.layer2_conv(pool1)\n",
    "        pool2 = F.max_pool2d(conv2, 2)\n",
    "        \n",
    "        conv3 = self.layer3_conv(pool2)\n",
    "        pool3 = F.max_pool2d(conv3, 2)\n",
    "\n",
    "        conv4 = self.layer4_conv(pool3)\n",
    "\n",
    "        convt1 = self.deconv1(conv4)\n",
    "        if convt1.shape[2:] != conv3.shape[2:]:\n",
    "            convt1 = F.interpolate(convt1, size=conv3.shape[2:], mode='bilinear', align_corners=True)\n",
    "        concat1 = torch.cat([convt1, conv3], dim=1)\n",
    "        conv5 = self.layer5_conv(concat1)\n",
    "        \n",
    "        convt2 = self.deconv2(conv5)\n",
    "        if convt2.shape[2:] != conv2.shape[2:]:\n",
    "            convt2 = F.interpolate(convt2, size=conv2.shape[2:], mode='bilinear', align_corners=True)\n",
    "        concat2 = torch.cat([convt2, conv2], dim=1)\n",
    "        conv6 = self.layer6_conv(concat2)\n",
    "\n",
    "        convt3 = self.deconv3(conv6)\n",
    "        if convt3.shape[2:] != conv1_2.shape[2:]:\n",
    "            convt3 = F.interpolate(convt3, size=conv1_2.shape[2:], mode='bilinear', align_corners=True)\n",
    "        concat3 = torch.cat([convt3, conv1_2], dim=1)\n",
    "        conv7 = self.layer7_conv(concat3)\n",
    "\n",
    "        conv8 = self.layer8_conv(conv7)\n",
    "        outp = self.sigmoid(conv8)\n",
    "        return outp\n",
    "model = UnetS3()\n",
    "inp = torch.rand(10, 1, 300, 300)\n",
    "outp = model(inp)\n",
    "print(\"输出形状:\", outp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaUnetS1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MetaUnetS1, self).__init__()\n",
    "        self.pointwise = nn.Conv2d(\n",
    "            2,\n",
    "            12,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=False\n",
    "        )\n",
    "        self.layer2_conv = double_conv2d_bn(12, 24)\n",
    "        self.layer3_conv = double_conv2d_bn(24, 12)\n",
    "        self.layer4_conv = nn.Conv2d(12,3,kernel_size=3,\n",
    "                                     stride=1,padding=1,bias=True)\n",
    "        \n",
    "        self.deconv1 = deconv2d_bn(24, 12)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        conv1_2 = self.pointwise(x)\n",
    "        pool1 = F.max_pool2d(conv1_2, 2)\n",
    "        \n",
    "        conv2 = self.layer2_conv(pool1)\n",
    "        convt1 = self.deconv1(conv2)\n",
    "        concat1 = torch.cat([convt1, conv1_2], dim=1)\n",
    "        conv3 = self.layer3_conv(concat1)\n",
    "        \n",
    "        conv4 = self.layer4_conv(conv3)\n",
    "        outp = self.sigmoid(conv4)\n",
    "        return outp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出形状: torch.Size([1, 4, 300, 300])\n"
     ]
    }
   ],
   "source": [
    "class MetaUnetS2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MetaUnetS2, self).__init__()\n",
    "        self.pointwise = nn.Conv2d(\n",
    "            2,\n",
    "            12,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=False\n",
    "        )\n",
    "        self.layer2_conv = double_conv2d_bn(12, 24)\n",
    "        self.layer3_conv = double_conv2d_bn(24, 48)\n",
    "        self.layer4_conv = double_conv2d_bn(48, 24)\n",
    "        self.layer5_conv = double_conv2d_bn(24, 12)\n",
    "        self.layer6_conv = nn.Conv2d(12,4,kernel_size=3,\n",
    "                                     stride=1,padding=1,bias=True)\n",
    "        \n",
    "        self.deconv1 = deconv2d_bn(48, 24)\n",
    "        self.deconv2 = deconv2d_bn(24, 12)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        conv1_2 = self.pointwise(x)\n",
    "        pool1 = F.max_pool2d(conv1_2, 2)\n",
    "\n",
    "        conv2 = self.layer2_conv(pool1)\n",
    "        pool2 = F.max_pool2d(conv2, 2)\n",
    "        conv3 = self.layer3_conv(pool2)\n",
    "        convt1 = self.deconv1(conv3)\n",
    "        concat1 = torch.cat([convt1, conv2], dim=1)\n",
    "        conv4 = self.layer4_conv(concat1)\n",
    "        convt2 = self.deconv2(conv4)\n",
    "        concat2 = torch.cat([convt2, conv1_2], dim=1)\n",
    "        conv5 = self.layer5_conv(concat2)\n",
    "        conv6 = self.layer6_conv(conv5)\n",
    "\n",
    "        outp = self.sigmoid(conv6)\n",
    "        return outp\n",
    "model = MetaUnetS2()\n",
    "inp = torch.rand(1, 2, 300, 300)\n",
    "outp = model(inp)\n",
    "print(\"输出形状:\", outp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x00000287A2CD4E80>\n",
      "Model Inference\n",
      "Benchmark model inference speed\n",
      "  11.47 ms\n",
      "  1 measurement, 100 runs , 1 thread\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.utils.benchmark.utils.common.Measurement object at 0x00000287A2CD4E80>\n",
       "Model Inference\n",
       "Benchmark model inference speed\n",
       "  11.47 ms\n",
       "  1 measurement, 100 runs , 1 thread"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.benchmark import Timer\n",
    "\n",
    "def benchmark_model(model, input_size, device='cuda', num_threads=1):\n",
    "    \"\"\"\n",
    "    使用PyTorch官方基准测试工具\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # 准备输入\n",
    "    if device == 'cuda':\n",
    "        x = torch.randn(input_size).cuda()\n",
    "    else:\n",
    "        x = torch.randn(input_size)\n",
    "    \n",
    "    # 定义测试函数\n",
    "    def model_inference():\n",
    "        with torch.no_grad():\n",
    "            return model(x)\n",
    "    \n",
    "    # 创建计时器\n",
    "    timer = Timer(\n",
    "        stmt=\"model_inference()\",\n",
    "        globals={\"model_inference\": model_inference},\n",
    "        num_threads=num_threads,\n",
    "        label=\"Model Inference\",\n",
    "        description=\"Benchmark model inference speed\"\n",
    "    )\n",
    "    \n",
    "    # 运行基准测试\n",
    "    result = timer.timeit(100)  # 运行100次\n",
    "    \n",
    "    print(result)\n",
    "    return result\n",
    "\n",
    "# 使用示例\n",
    "model=MetaUnetS2()\n",
    "benchmark_model(model, (1, 2, 300, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "运算量：468.000M, 参数量：3.771K\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = MetaUnetS1()\n",
    "\n",
    "# 选择设备（GPU 如果可用，否则是 CPU）\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 将模型转移到设备\n",
    "model.to(device)\n",
    "\n",
    "# 设置模型为评估模式\n",
    "model.eval()\n",
    "\n",
    "input_tensor = torch.randn(1, 2, 400, 400).to(device)\n",
    "# 将模型移动到设备\n",
    "model = model.to(device)\n",
    "\n",
    "# 计算FLOPs和参数量\n",
    "flops, params = profile(model, inputs=(input_tensor,), verbose=False)\n",
    "# 将结果转为更易读的格式\n",
    "flops, params = clever_format([flops, params], '%.3f')\n",
    "\n",
    "# 打印结果\n",
    "print(f\"运算量：{flops}, 参数量：{params}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
