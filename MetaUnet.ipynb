{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "438120cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2490100f",
   "metadata": {},
   "source": [
    "定义训练会用到的几个计算函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4633523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segmentation_results(predictions):\n",
    "    segmentation_results = torch.argmax(predictions, dim=1)\n",
    "    return segmentation_results\n",
    "\n",
    "def get_predictions(output):\n",
    "    bs,c,h,w = output.size()\n",
    "    values, indices = output.cpu().max(1)\n",
    "    indices = indices.view(bs,h,w) # bs x h x w\n",
    "    return indices\n",
    "\n",
    "def calculate_miou(predictions, labels, num_classes):\n",
    "    miou_list = []\n",
    "    for i in range(predictions.shape[0]):\n",
    "        pred = predictions[i]\n",
    "        label = labels[i]\n",
    "        confusion = confusion_matrix(label.flatten(), pred.flatten(), labels=range(num_classes))\n",
    "        TP = np.diag(confusion)\n",
    "        FP = np.sum(confusion, axis=0) - TP\n",
    "        FN = np.sum(confusion, axis=1) - TP\n",
    "        union = TP + FP + FN\n",
    "        iou = TP / union\n",
    "        miou = np.nanmean(iou)\n",
    "        miou_list.append(miou)\n",
    "    return np.mean(miou_list)\n",
    "\n",
    "def extract_middle(images, size):\n",
    "    _,w,h = images.shape\n",
    "    # 计算起始和结束索引\n",
    "    start = (w - size) // 2\n",
    "    end = start + size\n",
    "\n",
    "    # 提取中间的200x200区域\n",
    "    middle_images = images[:, start:end, start:end]\n",
    "\n",
    "    return middle_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7984be8",
   "metadata": {},
   "source": [
    "通过随机搜索算法自动寻找图像中最佳的4个区域坐标，使得从这些区域提取的特征能够训练出性能最好的分割模型。\n",
    "原始PNG → 随机搜索 → 提取4个区域 → 计算差分 → (2,300,300)数据 → 训练分割模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "810e18e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始region: [(300, 3550, 1800, 5050), (100, 300, 1600, 1800), (3500, 3350, 5000, 4850), (3400, 150, 4900, 1650)]\n",
      "开始使用分割模型进行随机搜索...\n",
      "找到 806 个PNG文件\n",
      "有效数据对: 806\n",
      "最终有效数据: 806 个图像-标签对\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "随机搜索:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "提取区域数据...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 591/806 [02:37<00:57,  3.74it/s]\n",
      "随机搜索:   0%|          | 0/50 [02:39<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 630>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m最佳region已保存到 best_regions_segmentation.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 631\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[38;5;66;03m# 使用分割模型进行搜索\u001b[39;00m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m开始使用分割模型进行随机搜索...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 619\u001b[0m best_regions, best_metric_score, history \u001b[38;5;241m=\u001b[39m \u001b[43mefficient_random_search_with_segmentation_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    620\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_regions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_offset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\n\u001b[0;32m    621\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;66;03m# max(offset)= 70\u001b[39;00m\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m最佳结果: 指标得分=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_metric_score\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36mefficient_random_search_with_segmentation_model\u001b[1;34m(data_folder, base_regions, n_iter, max_offset, model_type, num_epochs)\u001b[0m\n\u001b[0;32m    479\u001b[0m     new_regions\u001b[38;5;241m.\u001b[39mappend(new_region)\n\u001b[0;32m    481\u001b[0m \u001b[38;5;66;03m# 使用分割模型评估\u001b[39;00m\n\u001b[1;32m--> 482\u001b[0m metric_score,model \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_regions_with_segmentation_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_regions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    486\u001b[0m history\u001b[38;5;241m.\u001b[39mappend((new_regions, metric_score))\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metric_score \u001b[38;5;241m>\u001b[39m best_metric_score:\n",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36mevaluate_regions_with_segmentation_model\u001b[1;34m(image_paths, labels, regions, model_type, test_size, model_params, num_epochs)\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m提取区域数据...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, img_path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(image_paths)):\n\u001b[1;32m--> 311\u001b[0m     result_array \u001b[38;5;241m=\u001b[39m \u001b[43mextract_four_regions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mregions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result_array \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;66;03m# 保存数据\u001b[39;00m\n\u001b[0;32m    314\u001b[0m         data_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_temp_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m06d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36mextract_four_regions\u001b[1;34m(image_path, output_path, regions)\u001b[0m\n\u001b[0;32m    504\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m无法打开图像: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    505\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 507\u001b[0m img_array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m regions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    510\u001b[0m     regions \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    511\u001b[0m         (\u001b[38;5;241m300\u001b[39m,\u001b[38;5;241m3550\u001b[39m,\u001b[38;5;241m1800\u001b[39m,\u001b[38;5;241m5050\u001b[39m),\n\u001b[0;32m    512\u001b[0m (\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m300\u001b[39m,\u001b[38;5;241m1600\u001b[39m,\u001b[38;5;241m1800\u001b[39m),\n\u001b[0;32m    513\u001b[0m (\u001b[38;5;241m3500\u001b[39m,\u001b[38;5;241m3350\u001b[39m,\u001b[38;5;241m5000\u001b[39m,\u001b[38;5;241m4850\u001b[39m),\n\u001b[0;32m    514\u001b[0m (\u001b[38;5;241m3400\u001b[39m,\u001b[38;5;241m150\u001b[39m,\u001b[38;5;241m4900\u001b[39m,\u001b[38;5;241m1650\u001b[39m),\n\u001b[0;32m    515\u001b[0m     ]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\PIL\\Image.py:719\u001b[0m, in \u001b[0;36mImage.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    717\u001b[0m     new[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtobytes(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 719\u001b[0m     new[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtobytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ArrayData(new), dtype)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\PIL\\Image.py:762\u001b[0m, in \u001b[0;36mImage.tobytes\u001b[1;34m(self, encoder_name, *args)\u001b[0m\n\u001b[0;32m    759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m args \u001b[38;5;241m==\u001b[39m ():\n\u001b[0;32m    760\u001b[0m     args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[1;32m--> 762\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    764\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\PIL\\ImageFile.py:239\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 239\u001b[0m         s \u001b[38;5;241m=\u001b[39m \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecodermaxblock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, struct\u001b[38;5;241m.\u001b[39merror) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;66;03m# truncated png/gif\u001b[39;00m\n\u001b[0;32m    242\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m LOAD_TRUNCATED_IMAGES:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\PIL\\PngImagePlugin.py:946\u001b[0m, in \u001b[0;36mPngImageFile.load_read\u001b[1;34m(self, read_bytes)\u001b[0m\n\u001b[0;32m    942\u001b[0m     read_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(read_bytes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__idat)\n\u001b[0;32m    944\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__idat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__idat \u001b[38;5;241m-\u001b[39m read_bytes\n\u001b[1;32m--> 946\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mread_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class CustomNPYDataset(Dataset):\n",
    "    def __init__(self, data_dir, label_dir, transform=None):\n",
    "        \"\"\"\n",
    "        初始化数据集\n",
    "        \n",
    "        参数:\n",
    "        data_dir: 存放(2,300,300)格式NPY数据的文件夹路径\n",
    "        label_dir: 存放分割掩码标签NPY文件的文件夹路径\n",
    "        transform: 用于数据增强和预处理的转换操作\n",
    "        \"\"\"\n",
    "        self.data_dir = data_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        # 获取数据文件名列表（.npy文件）\n",
    "        self.data_files = [f for f in os.listdir(data_dir) if f.endswith('.npy')]\n",
    "        # 获取标签文件名列表（.npy文件）\n",
    "        self.label_files = [f for f in os.listdir(label_dir) if f.endswith('.npy')]\n",
    "        \n",
    "        # 确保数据和标签文件数量一致且文件名对应\n",
    "        self.data_files.sort()\n",
    "        self.label_files.sort()\n",
    "        \n",
    "        if len(self.data_files) != len(self.label_files):\n",
    "            print(f\"警告: 数据文件数量({len(self.data_files)})与标签文件数量({len(self.label_files)})不一致\")\n",
    "        \n",
    "        # 只保留有对应标签的数据文件\n",
    "        self.valid_indices = []\n",
    "        for i, data_file in enumerate(self.data_files):\n",
    "            # 假设数据和标签文件名相同或可以对应\n",
    "            label_file = data_file  # 或者根据您的命名规则调整\n",
    "            \n",
    "            if label_file in self.label_files:\n",
    "                self.valid_indices.append(i)\n",
    "            else:\n",
    "                print(f\"警告: 数据文件 {data_file} 没有对应的标签文件\")\n",
    "        \n",
    "        print(f\"有效数据-标签对数量: {len(self.valid_indices)}\")\n",
    "\n",
    "    def pad(self, M):\n",
    "        bs,c,H,W = M.size()\n",
    "        # 计算需要补零的宽度和高度\n",
    "        pad_height = np.abs((H - W) // 2)  # 向上取整\n",
    "        pad_width = np.abs((W - H) // 2)  # 向上取整\n",
    "        # 如果高度小于宽度，我们需要在高度上补零\n",
    "        if H < W:\n",
    "            M = F.pad(M, (0, 0, pad_width, pad_width), 'constant', 0)\n",
    "        # 如果宽度小于高度，我们需要在宽度上补零\n",
    "        elif W < H:\n",
    "            M = F.pad(M, (pad_height, pad_height, 0, 0), 'constant', 0)\n",
    "        return M\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        返回数据集中有效样本的数量\n",
    "        \"\"\"\n",
    "        return len(self.valid_indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        返回一个样本的数据和标签\n",
    "        \"\"\"\n",
    "        # 获取有效索引\n",
    "        valid_idx = self.valid_indices[idx]\n",
    "        \n",
    "        # 获取文件名\n",
    "        data_file = self.data_files[valid_idx]\n",
    "        label_file = data_file  # 假设标签文件名与数据文件名相同\n",
    "        \n",
    "        # 构建完整路径\n",
    "        data_path = os.path.join(self.data_dir, data_file)\n",
    "        label_path = os.path.join(self.label_dir, label_file)\n",
    "        \n",
    "        # 加载数据 (形状应为 (2, 300, 300))\n",
    "        data = np.load(data_path)\n",
    "        \n",
    "        # 加载标签 (形状应为 (300, 300) 或类似)\n",
    "        label = np.load(label_path)\n",
    "        label = torch.from_numpy(label)\n",
    "        label = self.pad(label.unsqueeze(0).unsqueeze(0)).squeeze(0).squeeze(0)\n",
    "        label = F.interpolate(label.unsqueeze(0).unsqueeze(0), size=(300, 300), mode='nearest').squeeze(0).squeeze(0)\n",
    "        # 转换为PyTorch张量\n",
    "        data_tensor = torch.from_numpy(data).float()\n",
    "        label_tensor = label.long()\n",
    "        \n",
    "        # 确保数据形状正确\n",
    "        if data_tensor.dim() == 2:\n",
    "            # 如果是单通道，添加通道维度\n",
    "            data_tensor = data_tensor.unsqueeze(0)\n",
    "        \n",
    "        # 确保标签形状正确\n",
    "        if label_tensor.dim() == 3 and label_tensor.shape[0] == 1:\n",
    "            # 如果标签有单通道维度，移除它\n",
    "            label_tensor = label_tensor.squeeze(0)\n",
    "        \n",
    "        # 应用转换操作\n",
    "        if self.transform:\n",
    "            data_tensor = self.transform(data_tensor)\n",
    "        \n",
    "        return data_tensor, label_tensor\n",
    "\n",
    "\n",
    "class depthwise_separable_conv(nn.Module):\n",
    "    \"\"\"MobileNet V1风格的深度可分离卷积块\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "        super().__init__()\n",
    "        # 深度卷积\n",
    "        self.depthwise = nn.Conv2d(\n",
    "            in_channels,\n",
    "            in_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            groups=in_channels,  # 关键参数：分组数=输入通道数\n",
    "            bias=False\n",
    "        )\n",
    "        # 逐点卷积\n",
    "        self.pointwise = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.depthwise(x)))  # 深度卷积+BN+ReLU\n",
    "        x = F.relu(self.bn2(self.pointwise(x)))  # 逐点卷积+BN+ReLU\n",
    "        return x\n",
    "\n",
    "class double_conv2d_bn(nn.Module):\n",
    "    \"\"\"双深度可分离卷积块（替换原始双标准卷积）\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, strides=1, padding=1):\n",
    "        super().__init__()\n",
    "        # 第一个深度可分离卷积\n",
    "        self.conv1 = depthwise_separable_conv(\n",
    "            in_channels, \n",
    "            out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=strides,\n",
    "            padding=padding\n",
    "        )\n",
    "        # 第二个深度可分离卷积\n",
    "        self.conv2 = depthwise_separable_conv(\n",
    "            out_channels,\n",
    "            out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=strides,\n",
    "            padding=padding\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "\n",
    "class deconv2d_bn(nn.Module):\n",
    "    \"\"\"反卷积块（保持原结构不变）\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=2, strides=2):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.ConvTranspose2d(\n",
    "            in_channels, out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=strides, bias=True\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.relu(self.bn1(self.conv1(x)))\n",
    "\n",
    "\n",
    "class NewUnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NewUnet, self).__init__()\n",
    "        # self.mycustomlayer = MyCustomLayer()\n",
    "        # self.layer1_conv = double_conv2d_bn(1, 12)\n",
    "        self.pointwise = nn.Conv2d(\n",
    "            2,\n",
    "            12,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=False\n",
    "        )\n",
    "        self.layer2_conv = double_conv2d_bn(12, 24)\n",
    "        self.layer3_conv = double_conv2d_bn(24, 12)\n",
    "        self.layer4_conv = nn.Conv2d(12,3,kernel_size=3,\n",
    "                                     stride=1,padding=1,bias=True)\n",
    "        \n",
    "        self.deconv1 = deconv2d_bn(24, 12)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # conv1, PSF, aft_conv = self.mycustomlayer(x)          #用于训练MetaUnet,后接conv1_2 = self.pointwise(conv1)\n",
    "        #conv1_2 = self.layer1_conv(x)                          #用于训练传统U-Net \n",
    "        conv1_2 = self.pointwise(x)\n",
    "        pool1 = F.max_pool2d(conv1_2, 2)\n",
    "        \n",
    "        conv2 = self.layer2_conv(pool1)\n",
    "        convt1 = self.deconv1(conv2)\n",
    "        concat1 = torch.cat([convt1, conv1_2], dim=1)\n",
    "        conv3 = self.layer3_conv(concat1)\n",
    "        \n",
    "        conv4 = self.layer4_conv(conv3)\n",
    "        outp = self.sigmoid(conv4)\n",
    "        return outp\n",
    "\n",
    "# ===============================\n",
    "# 自定义训练和评估函数\n",
    "# ===============================\n",
    "\n",
    "class CustomSegmentationTrainer:\n",
    "    def __init__(self, model, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.model.to(device)\n",
    "        \n",
    "    def train_epoch(self, dataloader, optimizer, criterion):\n",
    "        \"\"\"训练一个epoch\"\"\"\n",
    "        self.model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(dataloader):\n",
    "            data, target = data.to(self.device), target.to(self.device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = self.model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        return running_loss / len(dataloader)\n",
    "    \n",
    "    def evaluate(self, dataloader, criterion):\n",
    "        \"\"\"评估模型\"\"\"\n",
    "        self.model.eval()\n",
    "        running_loss = 0.0\n",
    "        total_pixels = 0\n",
    "        correct_pixels = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, target in dataloader:\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                output = self.model(data)\n",
    "                loss = criterion(output, target)\n",
    "                running_loss += loss.item()\n",
    "                \n",
    "                # 计算像素准确率\n",
    "                pred = output.argmax(dim=1)\n",
    "                correct_pixels += (pred == target).sum().item()\n",
    "                total_pixels += target.numel()\n",
    "        \n",
    "        accuracy = correct_pixels / total_pixels\n",
    "        return running_loss / len(dataloader), accuracy\n",
    "\n",
    "\n",
    "    \n",
    "def calculate_miou(predictions, labels, num_classes):\n",
    "    miou_list = []\n",
    "    for i in range(predictions.shape[0]):\n",
    "        pred = predictions[i]\n",
    "        label = labels[i]\n",
    "        confusion = confusion_matrix(label.flatten(), pred.flatten(), labels=range(num_classes))\n",
    "        TP = np.diag(confusion)\n",
    "        FP = np.sum(confusion, axis=0) - TP\n",
    "        FN = np.sum(confusion, axis=1) - TP\n",
    "        union = TP + FP + FN\n",
    "        iou = TP / union\n",
    "        miou = np.nanmean(iou)\n",
    "        miou_list.append(miou)\n",
    "    return np.mean(miou_list)\n",
    "\n",
    "# ===============================\n",
    "# 使用分割模型的评估函数\n",
    "# ===============================\n",
    "\n",
    "def evaluate_regions_with_segmentation_model(image_paths, labels, regions, model_type='segmentation', \n",
    "                                           test_size=0.2, model_params=None, num_epochs=5):\n",
    "    \"\"\"\n",
    "    使用分割模型评估region精度\n",
    "    \n",
    "    参数:\n",
    "    image_paths: 图像路径列表\n",
    "    labels: 标签列表（这里labels参数可能不需要，因为标签从文件加载）\n",
    "    regions: 区域坐标\n",
    "    model_type: 模型类型\n",
    "    test_size: 测试集比例\n",
    "    model_params: 模型参数\n",
    "    num_epochs: 训练轮数\n",
    "    \"\"\"\n",
    "    # 创建临时目录来保存提取的数据\n",
    "    import tempfile\n",
    "    import shutil\n",
    "    \n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    data_temp_dir = os.path.join(temp_dir, 'data')\n",
    "    label_temp_dir = os.path.join(temp_dir, 'labels')\n",
    "    os.makedirs(data_temp_dir)\n",
    "    os.makedirs(label_temp_dir)\n",
    "    \n",
    "    try:\n",
    "        # 提取所有图像的区域并保存为npy文件\n",
    "        print(\"提取区域数据...\")\n",
    "        for i, img_path in enumerate(tqdm(image_paths)):\n",
    "            result_array = extract_four_regions(img_path, regions=regions)\n",
    "            if result_array is not None:\n",
    "                # 保存数据\n",
    "                data_path = os.path.join(data_temp_dir, f'data_{i:06d}.npy')\n",
    "                np.save(data_path, result_array)\n",
    "                \n",
    "                # 这里需要处理标签 - 假设labels包含标签文件路径\n",
    "                # 根据你的数据格式调整\n",
    "                if i < len(labels):\n",
    "                    # 复制标签文件到临时目录\n",
    "                    label_src = labels[i] if isinstance(labels[i], str) else None\n",
    "                    if label_src and os.path.exists(label_src):\n",
    "                        label_dst = os.path.join(label_temp_dir, f'data_{i:06d}.npy')\n",
    "                        shutil.copy2(label_src, label_dst)\n",
    "        \n",
    "        # 创建数据集\n",
    "        dataset = CustomNPYDataset(data_temp_dir, label_temp_dir)\n",
    "        \n",
    "        if len(dataset) == 0:\n",
    "            return 0\n",
    "        \n",
    "        # 分割训练测试集\n",
    "        dataset_size = len(dataset)\n",
    "        train_size = int((1 - test_size) * dataset_size)\n",
    "        test_size = dataset_size - train_size\n",
    "        train_dataset, test_dataset = torch.utils.data.random_split(\n",
    "            dataset, [train_size, test_size], \n",
    "            generator=torch.Generator().manual_seed(42)\n",
    "        )\n",
    "        \n",
    "        # 创建数据加载器\n",
    "        train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        # 初始化模型\n",
    "        model = NewUnet()  \n",
    "        trainer = CustomSegmentationTrainer(model)\n",
    "        \n",
    "        # 定义优化器和损失函数\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        class_weights = torch.tensor([1.0, 4.0, 20.0], dtype=torch.float32)  # 示例权重，根据类别频率调整\n",
    "        class_weights = class_weights.to(device)  # 将权重移动到设备上\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights)  # 使用加权交叉熵损失\n",
    "        # 训练模型\n",
    "        print(\"训练分割模型...\")\n",
    "        for epoch in range(num_epochs):\n",
    "            train_loss = trainer.train_epoch(train_loader, optimizer, criterion)\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {train_loss:.4f}\")\n",
    "        \n",
    "        # 评估模型\n",
    "        test_loss, test_accuracy = trainer.evaluate(test_loader, criterion)\n",
    "        miou_list=[]\n",
    "        val_loss=0.0\n",
    "        with torch.no_grad():\n",
    "            for data in test_loader:\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                predictions = get_segmentation_results(outputs)\n",
    "                predictions = predictions.cpu().numpy()\n",
    "                labels = labels.cpu().numpy()\n",
    "                miou = calculate_miou(predictions, labels, num_classes=3)\n",
    "                miou_list.append(miou)\n",
    "                val_loss += loss.item()\n",
    "                mean_miou = np.mean(miou_list)\n",
    "        \n",
    "        print(f\"测试准确率: {test_accuracy:.4f}, 自定义指标: {mean_miou:.4f}\")\n",
    "        \n",
    "        return mean_miou,model\n",
    "        \n",
    "    finally:\n",
    "        # 清理临时文件\n",
    "        shutil.rmtree(temp_dir)\n",
    "\n",
    "# ===============================\n",
    "# 数据加载和处理函数（保持不变）\n",
    "# ===============================\n",
    "\n",
    "def load_data_from_folder(data_folder):\n",
    "    \"\"\"从文件夹加载图像和标签\"\"\"\n",
    "    image_paths = []\n",
    "    label_paths = []\n",
    "    \n",
    "    if not os.path.exists(data_folder):\n",
    "        raise ValueError(f\"数据文件夹不存在: {data_folder}\")\n",
    "    \n",
    "    png_files = [f for f in os.listdir(data_folder) if f.lower().endswith('.png')]\n",
    "    \n",
    "    print(f\"找到 {len(png_files)} 个PNG文件\")\n",
    "    \n",
    "    for png_file in sorted(png_files):\n",
    "        img_path = os.path.join(data_folder, png_file)\n",
    "        image_paths.append(img_path)\n",
    "        \n",
    "        base_name = os.path.splitext(png_file)[0]\n",
    "        npy_file = base_name + '.npy'\n",
    "        label_path = os.path.join(data_folder, npy_file)\n",
    "        \n",
    "        if os.path.exists(label_path):\n",
    "            label_paths.append(label_path)\n",
    "        else:\n",
    "            print(f\"警告: 找不到标签文件 {label_path}\")\n",
    "            label_paths.append(None)\n",
    "    \n",
    "    valid_indices = [i for i, label_path in enumerate(label_paths) if label_path is not None]\n",
    "    image_paths = [image_paths[i] for i in valid_indices]\n",
    "    label_paths = [label_paths[i] for i in valid_indices]\n",
    "    \n",
    "    print(f\"有效数据对: {len(image_paths)}\")\n",
    "    \n",
    "    return image_paths, label_paths\n",
    "\n",
    "def load_labels(label_paths):\n",
    "    \"\"\"从NPY文件加载标签\"\"\"\n",
    "    labels = []\n",
    "    \n",
    "    for label_path in tqdm(label_paths, desc=\"加载标签\"):\n",
    "        try:\n",
    "            label = np.load(label_path)\n",
    "            if isinstance(label, np.ndarray) and label.size > 1:\n",
    "                label = label.item() if label.size == 1 else label[0]\n",
    "            labels.append(label)\n",
    "        except Exception as e:\n",
    "            print(f\"加载标签失败 {label_path}: {e}\")\n",
    "            labels.append(None)\n",
    "    \n",
    "    valid_indices = [i for i, label in enumerate(labels) if label is not None]\n",
    "    valid_labels = [labels[i] for i in valid_indices]\n",
    "    \n",
    "    return valid_labels, valid_indices\n",
    "\n",
    "# ===============================\n",
    "# 使用分割模型的随机搜索函数\n",
    "# ===============================\n",
    "\n",
    "def efficient_random_search_with_segmentation_model(data_folder, base_regions, n_iter=10, max_offset=100, \n",
    "                                                   model_type='segmentation', num_epochs=3):\n",
    "    \"\"\"\n",
    "    使用分割模型进行高效随机搜索\n",
    "    \"\"\"\n",
    "    # 从文件夹加载数据\n",
    "    image_paths, label_paths = load_data_from_folder(data_folder)\n",
    "    \n",
    "    if len(image_paths) == 0:\n",
    "        raise ValueError(\"没有有效的数据对可用于训练\")\n",
    "    \n",
    "    print(f\"最终有效数据: {len(image_paths)} 个图像-标签对\")\n",
    "    \n",
    "    best_metric_score = 0\n",
    "    best_regions = base_regions.copy()\n",
    "    history = []\n",
    "    \n",
    "    for i in tqdm(range(n_iter), desc=\"随机搜索\"):\n",
    "        # 生成随机偏移\n",
    "        new_regions = []\n",
    "        for j, (x1, y1, x2, y2) in enumerate(base_regions):\n",
    "            dx1 = np.random.randint(-max_offset, max_offset+1)\n",
    "            dy1 = np.random.randint(-max_offset, max_offset+1)\n",
    "            dx2 = np.random.randint(-max_offset, max_offset+1)\n",
    "            dy2 = np.random.randint(-max_offset, max_offset+1)\n",
    "            \n",
    "            new_region = (\n",
    "                max(0, x1 + dx1),\n",
    "                max(0, y1 + dy1),\n",
    "                x2 + dx2,\n",
    "                y2 + dy2\n",
    "            )\n",
    "            new_regions.append(new_region)\n",
    "        \n",
    "        # 使用分割模型评估\n",
    "        metric_score,model = evaluate_regions_with_segmentation_model(\n",
    "            image_paths, label_paths, new_regions, \n",
    "            model_type=model_type, num_epochs=num_epochs\n",
    "        )\n",
    "        history.append((new_regions, metric_score))\n",
    "        \n",
    "        if metric_score > best_metric_score:\n",
    "            best_metric_score = metric_score\n",
    "            best_regions = new_regions.copy()\n",
    "            print(f\"迭代 {i}: 新最佳指标得分 {best_metric_score:.4f}\")\n",
    "            torch.save(model, './best_model.pth')\n",
    "    return best_regions, best_metric_score, history\n",
    "\n",
    "# ===============================\n",
    "# 区域提取函数（保持不变）\n",
    "# ===============================\n",
    "\n",
    "def extract_four_regions(image_path, output_path=None, regions=None):\n",
    "    \"\"\"从PNG图像中截取四个区域并返回result_array\"\"\"\n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "    except Exception as e:\n",
    "        print(f\"无法打开图像: {e}\")\n",
    "        return None\n",
    "    \n",
    "    img_array = np.array(img)\n",
    "    \n",
    "    if regions is None:\n",
    "        regions = [\n",
    "            (300,3550,1800,5050),\n",
    "    (100,300,1600,1800),\n",
    "    (3500,3350,5000,4850),\n",
    "    (3400,150,4900,1650),\n",
    "        ]\n",
    "    \n",
    "    if len(regions) != 4:\n",
    "        print(\"需要提供四个区域坐标\")\n",
    "        return None\n",
    "    \n",
    "    extracted_regions = []\n",
    "    for i, (x1, y1, x2, y2) in enumerate(regions):\n",
    "        if (x1 < 0 or y1 < 0 or x2 > img_array.shape[1] or y2 > img_array.shape[0]):\n",
    "            print(f\"区域 {i+1} 超出图像范围\")\n",
    "            continue\n",
    "        \n",
    "        region = img_array[y1:y2, x1:x2]\n",
    "\n",
    "        pad_width=0\n",
    "        top_pad = np.tile(region[0:1, :], (pad_width, 1))\n",
    "        bottom_pad = np.tile(region[-1:, :], (pad_width, 1))\n",
    "        region_padded = np.vstack([top_pad, region, bottom_pad])\n",
    "        \n",
    "        left_pad = np.tile(region_padded[:, 0:1], (1, pad_width))\n",
    "        right_pad = np.tile(region_padded[:, -1:], (1, pad_width))\n",
    "        region_padded = np.hstack([left_pad, region_padded, right_pad])\n",
    "\n",
    "        if region_padded.shape[0] != 300 or region_padded.shape[1] != 300:\n",
    "            region_img = Image.fromarray(region_padded)\n",
    "            region_img = region_img.resize((300, 300))\n",
    "            region = np.array(region_img)\n",
    "        \n",
    "        extracted_regions.append(region)\n",
    "    \n",
    "    if len(extracted_regions) == 4:\n",
    "        array = np.stack(extracted_regions, axis=0).astype(np.float32)\n",
    "        diff1 = array[0]- array[2]\n",
    "        diff2 = array[1]-array[3]\n",
    "        \n",
    "        result_array = np.stack([diff1, diff2], axis=0)\n",
    "        \n",
    "        if output_path:\n",
    "            np.save(output_path, result_array)\n",
    "            print(f\"已保存到: {output_path}\")\n",
    "        \n",
    "        return result_array\n",
    "    else:\n",
    "        print(\"无法提取四个有效区域\")\n",
    "        return None\n",
    "\n",
    "def extract_regions_from_array(img_array, regions):\n",
    "    \"\"\"从已加载的图像数组中提取区域\"\"\"\n",
    "    extracted_regions = []\n",
    "    for i, (x1, y1, x2, y2) in enumerate(regions):\n",
    "        if (x1 < 0 or y1 < 0 or x2 > img_array.shape[1] or y2 > img_array.shape[0]):\n",
    "            return None\n",
    "        \n",
    "        region = img_array[y1:y2, x1:x2]\n",
    "\n",
    "        pad_width=0\n",
    "        top_pad = np.tile(region[0:1, :], (pad_width, 1))\n",
    "        bottom_pad = np.tile(region[-1:, :], (pad_width, 1))\n",
    "        region_padded = np.vstack([top_pad, region, bottom_pad])\n",
    "        \n",
    "        left_pad = np.tile(region_padded[:, 0:1], (1, pad_width))\n",
    "        right_pad = np.tile(region_padded[:, -1:], (1, pad_width))\n",
    "        region_padded = np.hstack([left_pad, region_padded, right_pad])\n",
    "\n",
    "        if region_padded.shape[0] != 300 or region_padded.shape[1] != 300:\n",
    "            region_img = Image.fromarray(region_padded)\n",
    "            region_img = region_img.resize((300, 300))\n",
    "            region = np.array(region_img)\n",
    "        \n",
    "        extracted_regions.append(region)\n",
    "    \n",
    "    if len(extracted_regions) == 4:\n",
    "        array = np.stack(extracted_regions, axis=0).astype(np.float32)\n",
    "        diff1 = array[0]- array[2]\n",
    "        diff2 = array[1]-array[3]\n",
    "        \n",
    "        result_array = np.stack([diff1, diff2], axis=0)\n",
    "        \n",
    "        return result_array\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# ===============================\n",
    "# 主函数\n",
    "# ===============================\n",
    "\n",
    "def main():\n",
    "    # 数据文件夹路径\n",
    "    data_folder = r\"C:\\Users\\86155\\Desktop\\20250709\\twolayer3\\processed\"\n",
    "    \n",
    "    # 基础region坐标\n",
    "    base_regions = [\n",
    "       (300,3550,1800,5050),\n",
    "    (100,300,1600,1800),\n",
    "    (3500,3350,5000,4850),\n",
    "    (3400,150,4900,1650),\n",
    "    ]\n",
    "   \n",
    "    \n",
    "\n",
    "    print(\"初始region:\", base_regions)\n",
    "    \n",
    "    # 使用分割模型进行搜索\n",
    "    print(\"开始使用分割模型进行随机搜索...\")\n",
    "    best_regions, best_metric_score, history = efficient_random_search_with_segmentation_model(\n",
    "        data_folder, base_regions, n_iter=50, max_offset=50, num_epochs=50\n",
    "    )\n",
    "    # max(offset)= 70\n",
    "    print(f\"最佳结果: 指标得分={best_metric_score:.4f}\")\n",
    "    print(f\"最佳region: {best_regions}\")\n",
    "    \n",
    "    # 保存最佳结果\n",
    "    np.save(\"best_regions_segmentation.npy\", np.array(best_regions))\n",
    "    print(\"最佳region已保存到 best_regions_segmentation.npy\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74ea6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出形状: torch.Size([10, 3, 300, 300])\n"
     ]
    }
   ],
   "source": [
    "class UnetS1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UnetS1, self).__init__()\n",
    "        # self.mycustomlayer = MyCustomLayer()\n",
    "        self.layer1_conv = double_conv2d_bn(1, 12)\n",
    "        self.pointwise = nn.Conv2d(\n",
    "            2,\n",
    "            12,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=False\n",
    "        )\n",
    "        self.layer2_conv = double_conv2d_bn(12, 24)\n",
    "        self.layer3_conv = double_conv2d_bn(24, 12)\n",
    "        # self.layer3_conv = double_conv2d_bn(12, 12)\n",
    "        self.layer4_conv = nn.Conv2d(12,3,kernel_size=3,\n",
    "                                     stride=1,padding=1,bias=True)\n",
    "        \n",
    "        self.deconv1 = deconv2d_bn(24, 12)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):      \n",
    "        conv1_2 = self.layer1_conv(x)\n",
    "        pool1 = F.max_pool2d(conv1_2, 2)\n",
    "        \n",
    "        conv2 = self.layer2_conv(pool1)\n",
    "        \n",
    "        convt1 = self.deconv1(conv2)\n",
    "        concat1 = torch.cat([convt1, conv1_2], dim=1)\n",
    "        conv3 = self.layer3_conv(concat1)\n",
    "        \n",
    "        conv4 = self.layer4_conv(conv3)\n",
    "        outp = self.sigmoid(conv4)\n",
    "        return outp\n",
    "model = UnetS1()\n",
    "inp = torch.rand(10, 1, 300, 300)\n",
    "outp = model(inp)\n",
    "print(\"输出形状:\", outp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc670522",
   "metadata": {},
   "source": [
    "数据准备，为图像数据集创建坐标标签，适用于需要空间位置信息的计算机视觉任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ecc5ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总坐标点数: 961\n",
      "坐标映射文件创建完成\n",
      "   image_id                                         image_path  x_coord  \\\n",
      "0         1  C:\\Users\\86155\\Desktop\\20250709\\dataset_final\\...      -30   \n",
      "1         2  C:\\Users\\86155\\Desktop\\20250709\\dataset_final\\...      -30   \n",
      "2         3  C:\\Users\\86155\\Desktop\\20250709\\dataset_final\\...      -30   \n",
      "3         4  C:\\Users\\86155\\Desktop\\20250709\\dataset_final\\...      -30   \n",
      "4         5  C:\\Users\\86155\\Desktop\\20250709\\dataset_final\\...      -30   \n",
      "\n",
      "   y_coord coord_label  \n",
      "0      -30   (-30,-30)  \n",
      "1      -28   (-30,-28)  \n",
      "2      -26   (-30,-26)  \n",
      "3      -24   (-30,-24)  \n",
      "4      -22   (-30,-22)  \n",
      "...\n",
      "     image_id                                         image_path  x_coord  \\\n",
      "956       957  C:\\Users\\86155\\Desktop\\20250709\\dataset_final\\...       30   \n",
      "957       958  C:\\Users\\86155\\Desktop\\20250709\\dataset_final\\...       30   \n",
      "958       959  C:\\Users\\86155\\Desktop\\20250709\\dataset_final\\...       30   \n",
      "959       960  C:\\Users\\86155\\Desktop\\20250709\\dataset_final\\...       30   \n",
      "960       961  C:\\Users\\86155\\Desktop\\20250709\\dataset_final\\...       30   \n",
      "\n",
      "     y_coord coord_label  \n",
      "956       22     (30,22)  \n",
      "957       24     (30,24)  \n",
      "958       26     (30,26)  \n",
      "959       28     (30,28)  \n",
      "960       30     (30,30)  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 生成所有坐标点（按顺序）\n",
    "coordinates = []\n",
    "for x in range(0, 31):  # -30 到 30\n",
    "    for y in range(0, 31):  # -30 到 30\n",
    "        x_pos=2*(x-15)\n",
    "        y_pos=2*(y-15)\n",
    "        coordinates.append((x_pos, y_pos))\n",
    "\n",
    "print(f\"总坐标点数: {len(coordinates)}\")  # 61 * 61 = 3721\n",
    "\n",
    "# 创建映射关系（假设坐标和图片是按相同顺序排列的）\n",
    "data = []\n",
    "for i, (x, y) in enumerate(coordinates, 1):\n",
    "    img_name = f\"frame_{i}.png\"  # frame_1.png, frame_2.png, ..., frame_961.png\n",
    "    img_path = os.path.join(r'C:\\Users\\86155\\Desktop\\20250709\\dataset_final\\train\\data_ori', img_name)\n",
    "    \n",
    "    data.append({\n",
    "        'image_id': i,\n",
    "        'image_path': img_path,\n",
    "        'x_coord': x,\n",
    "        'y_coord': y,\n",
    "        'coord_label': f\"({x},{y})\"\n",
    "    })\n",
    "\n",
    "# 创建DataFrame并保存\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('coordinate_mapping.csv', index=False)\n",
    "print(\"坐标映射文件创建完成\")\n",
    "print(df.head())\n",
    "print(\"...\")\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fafa5b",
   "metadata": {},
   "source": [
    "用于在图像分割结果中识别特定类别的连通区域，并计算这些区域的质心坐标。\n",
    "only_largest=True参数用于指定只返回面积最大的连通区域的质心。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e92f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import ndimage\n",
    "import json\n",
    "import cv2\n",
    "def find_class_centroids(segmentation_map, target_class=2, min_area=10, only_largest=True):\n",
    "    \"\"\"\n",
    "    在分割图中寻找特定类别（默认为2）的连通区域并计算质心\n",
    "    \n",
    "    Args:\n",
    "        segmentation_map: 分割结果图 (H, W)\n",
    "        target_class: 目标类别值\n",
    "        min_area: 最小区域面积（像素数）\n",
    "        only_largest: 如果为True，只返回最大区域的质心；否则返回所有区域的质心\n",
    "    \n",
    "    Returns:\n",
    "        centroids: 质心坐标列表 [(x1, y1), ...] （根据only_largest参数返回一个或多个）\n",
    "    \"\"\"\n",
    "    # 创建目标类别的二值掩码\n",
    "    binary_mask = (segmentation_map == target_class).astype(np.uint8)\n",
    "    \n",
    "    if np.sum(binary_mask) == 0:\n",
    "        return []\n",
    "    \n",
    "    # 使用连通组件分析找出所有独立区域\n",
    "    labeled_array, num_features = ndimage.label(binary_mask)\n",
    "    \n",
    "    regions_info = []  # 存储区域信息：面积、质心、掩码\n",
    "    \n",
    "    for label in range(1, num_features + 1):\n",
    "        # 提取当前标签的区域\n",
    "        region_mask = (labeled_array == label).astype(np.uint8)\n",
    "        area = np.sum(region_mask)\n",
    "        \n",
    "        # 过滤面积太小的区域\n",
    "        if area < min_area:\n",
    "            continue\n",
    "        \n",
    "        # 计算区域的矩（用于质心计算）\n",
    "        M = cv2.moments(region_mask)\n",
    "        \n",
    "        if M['m00'] != 0:\n",
    "            cx = M['m10'] / M['m00']\n",
    "            cy = M['m01'] / M['m00']\n",
    "            \n",
    "            regions_info.append({\n",
    "                'label': label,\n",
    "                'area': area,\n",
    "                'centroid': (cx, cy),\n",
    "                'region_mask': region_mask.copy()  # 保存掩码，便于后续可视化\n",
    "            })\n",
    "    \n",
    "    if not regions_info:\n",
    "        return []\n",
    "    \n",
    "    # 根据 only_largest 参数决定返回哪些质心\n",
    "    if only_largest:\n",
    "        # 找出面积最大的区域\n",
    "        largest_region = max(regions_info, key=lambda x: x['area'])\n",
    "        # 打印调试信息\n",
    "        # print(f\"找到{len(regions_info)}个{target_class}类区域，选取最大区域(面积={largest_region['area']})的质心\")\n",
    "        return [largest_region['centroid']], regions_info  # 返回质心列表和区域信息\n",
    "    else:\n",
    "        # 返回所有区域的质心\n",
    "        centroids = [info['centroid'] for info in regions_info]\n",
    "        return centroids, regions_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636aa1f6",
   "metadata": {},
   "source": [
    "批量处理测试图像，使用训练好的分割模型进行预测，保存分割结果、可视化图像，并提取特定类别（默认类别2）的区域质心信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af1d315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_all_segmentations(model, test_image_paths, regions, \n",
    "                           output_dir='./segmentation_results', device='cpu',only_largest_class2=True):\n",
    "    \"\"\"\n",
    "    批量保存所有分割结果\n",
    "    \n",
    "    Args:\n",
    "        model: 训练好的模型\n",
    "        test_image_paths: 测试图像路径列表\n",
    "        regions: 区域坐标列表\n",
    "        output_dir: 输出目录\n",
    "        device: 计算设备\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    # 创建输出目录\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    npy_dir = os.path.join(output_dir, 'npy_files')\n",
    "    vis_dir = os.path.join(output_dir, 'visualizations')\n",
    "    os.makedirs(npy_dir, exist_ok=True)\n",
    "    os.makedirs(vis_dir, exist_ok=True)\n",
    "    \n",
    "    centroids_records = []  # 记录所有质心结果\n",
    "    \n",
    "    for idx, img_path in enumerate(test_image_paths):\n",
    "        try:\n",
    "            # 1. 提取特征并预测\n",
    "            input_array = extract_four_regions(img_path, regions=regions)\n",
    "            if input_array is None:\n",
    "                continue\n",
    "                \n",
    "            input_tensor = torch.from_numpy(input_array).float().unsqueeze(0).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                output = model(input_tensor)\n",
    "                predictions = get_segmentation_results(output)\n",
    "                predictions_np = predictions.squeeze().cpu().numpy()\n",
    "            \n",
    "            # 2. 保存为.npy文件\n",
    "            base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "            npy_path = os.path.join(npy_dir, f'{base_name}_seg.npy')\n",
    "            np.save(npy_path, predictions_np)\n",
    "            \n",
    "            # 3. 计算数值2区域的质心\n",
    "            centroids, regions_info = find_class_centroids(\n",
    "                predictions_np, \n",
    "                target_class=2, \n",
    "                min_area=10, \n",
    "                only_largest=only_largest_class2  # 使用参数控制\n",
    "            )\n",
    "            \n",
    "            # 记录质心信息\n",
    "            for centroid in centroids:\n",
    "                centroids_records.append({\n",
    "                    'image_name': os.path.basename(img_path),\n",
    "                    'class': 2,\n",
    "                    'centroid_x': float(centroid[0]),\n",
    "                    'centroid_y': float(centroid[1]),\n",
    "                    'is_largest': True,  # 新增字段，标记是否为最大区域\n",
    "                    'region_count': len(regions_info) if regions_info else 0\n",
    "                })\n",
    "            \n",
    "            # 修改这里：传入regions_info给可视化函数\n",
    "            \n",
    "            if (idx + 1) % 10 == 0:\n",
    "                print(f\"已处理 {idx + 1}/{len(test_image_paths)} 张图像\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"处理 {img_path} 时出错: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # 5. 保存质心结果到CSV\n",
    "    if centroids_records:\n",
    "        df_centroids = pd.DataFrame(centroids_records)\n",
    "        csv_path = os.path.join(output_dir, 'class2_centroids.csv')\n",
    "        df_centroids.to_csv(csv_path, index=False, encoding='utf-8-sig')\n",
    "        print(f\"\\n质心结果已保存至: {csv_path}\")\n",
    "        print(f\"共找到 {len(df_centroids)} 个质心点\")\n",
    "    \n",
    "    # 6. 保存汇总统计信息\n",
    "    stats = {\n",
    "        'total_images': len(test_image_paths),\n",
    "        'processed_images': idx + 1,\n",
    "        'total_centroids_found': len(centroids_records),\n",
    "        'output_directory': output_dir\n",
    "    }\n",
    "    \n",
    "    stats_path = os.path.join(output_dir, 'processing_stats.json')\n",
    "    with open(stats_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(stats, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"\\n所有分割结果已保存至: {output_dir}\")\n",
    "    print(f\"NPY文件: {npy_dir}\")\n",
    "    \n",
    "    return df_centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54644f6",
   "metadata": {},
   "source": [
    "使用优化得到的最佳区域和训练好的分割模型，对测试数据集进行批量预测、保存分割结果，并提取特定类别区域的质心信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89215a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_with_best_results():\n",
    "    \"\"\"使用搜索得到的最佳区域和模型进行预测、保存和质心搜索\"\"\"\n",
    "    # [原有代码：加载路径、区域和模型...]\n",
    "    data_folder = r\"C:\\Users\\86155\\Desktop\\20250709\\dataset_final\\train\\data_ori\"\n",
    "    best_regions_path = \"best_regions_segmentation_U2.npy\"\n",
    "    if os.path.exists(best_regions_path):\n",
    "        best_regions = np.load(best_regions_path)\n",
    "        print(f\"加载最佳区域: {best_regions}\")\n",
    "    else:\n",
    "        print(\"找不到最佳区域文件，使用默认区域\")\n",
    "        best_regions = [\n",
    "            (5, 3350, 1605, 4950),\n",
    "    (80, 5, 1680, 1605),\n",
    "    (3220, 3520, 4820, 5120),\n",
    "    (3400, 140, 5000, 1740),\n",
    "        ]\n",
    "    best_model_path = \"./best_modelfind_U2.pth\"\n",
    "    \n",
    "    # 加载测试数据\n",
    "    test_image_paths, test_label_paths = load_data_from_folder(data_folder)\n",
    "    \n",
    "    if len(test_image_paths) == 0:\n",
    "        print(\"没有找到测试数据\")\n",
    "        return\n",
    "    \n",
    "    print(f\"找到 {len(test_image_paths)} 个测试样本\")\n",
    "    \n",
    "    # 新增：批量保存分割结果并搜索质心\n",
    "    print(\"\\n开始批量保存分割结果并进行质心搜索...\")\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = torch.load(best_model_path, map_location=device, weights_only=False)\n",
    "    \n",
    "    df_centroids = save_all_segmentations(\n",
    "        model=model,\n",
    "        test_image_paths=test_image_paths,\n",
    "        regions=best_regions,\n",
    "        output_dir='./segmentation_results_data',\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    # 可选：显示质心统计信息\n",
    "    if df_centroids is not None and not df_centroids.empty:\n",
    "        print(\"\\n质心统计信息:\")\n",
    "        print(f\"总质心数量: {len(df_centroids)}\")\n",
    "        print(f\"涉及图像数量: {df_centroids['image_name'].nunique()}\")\n",
    "        \n",
    "        # 每张图像的平均质心数\n",
    "        avg_centroids = df_centroids.groupby('image_name').size().mean()\n",
    "        print(f\"每张图像平均质心数: {avg_centroids:.2f}\")\n",
    "        \n",
    "        # 质心坐标范围\n",
    "        print(f\"X坐标范围: [{df_centroids['centroid_x'].min():.1f}, {df_centroids['centroid_x'].max():.1f}]\")\n",
    "        print(f\"Y坐标范围: [{df_centroids['centroid_y'].min():.1f}, {df_centroids['centroid_y'].max():.1f}]\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677784ba",
   "metadata": {},
   "source": [
    "执行质心坐标提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647d735e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # 使用最佳结果进行预测和可视化\n",
    "    main_with_best_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f329d5c1",
   "metadata": {},
   "source": [
    "用于加载、匹配、检查和可视化角度数据（来自CSV文件，包含图像文件名和对应的角度）和坐标数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40df4493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置中文显示（如果需要）\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 用来正常显示中文标签\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号\n",
    "\n",
    "class GazeDataProcessor:\n",
    "    \"\"\"视线数据处理和匹配类\"\"\"\n",
    "    \n",
    "    def __init__(self, angle_csv_path=None, coord_csv_path=None):\n",
    "        \"\"\"\n",
    "        初始化处理器\n",
    "        \n",
    "        参数:\n",
    "            angle_csv_path: 角度数据CSV文件路径\n",
    "            coord_csv_path: 坐标数据CSV文件路径\n",
    "        \"\"\"\n",
    "        self.angle_csv_path = angle_csv_path\n",
    "        self.coord_csv_path = coord_csv_path\n",
    "        self.df_angles = None\n",
    "        self.df_coords = None\n",
    "        self.df_merged = None\n",
    "        self.eye_points = None\n",
    "        self.screen_points = None\n",
    "        self.filenames = None\n",
    "        \n",
    "    def load_angle_data(self, csv_path=None, sep=',', path_col='image_path', \n",
    "                       angle_x_col='angle_x', angle_y_col='angle_y'):\n",
    "        \"\"\"\n",
    "        加载角度数据CSV\n",
    "        \n",
    "        参数:\n",
    "            csv_path: CSV文件路径\n",
    "            sep: 分隔符，默认为逗号\n",
    "            path_col: 图像路径列名\n",
    "            angle_x_col: X角度列名\n",
    "            angle_y_col: Y角度列名\n",
    "        \"\"\"\n",
    "        if csv_path is None:\n",
    "            csv_path = self.angle_csv_path\n",
    "            \n",
    "        print(f\"正在加载角度数据: {csv_path}\")\n",
    "        \n",
    "        try:\n",
    "            self.df_angles = pd.read_csv(csv_path, sep=sep)\n",
    "            print(f\"角度数据列: {list(self.df_angles.columns)}\")\n",
    "            \n",
    "            # 重命名列以便统一处理\n",
    "            if path_col in self.df_angles.columns:\n",
    "                self.df_angles = self.df_angles.rename(columns={\n",
    "                    path_col: 'image_path',\n",
    "                    angle_x_col: 'angle_x',\n",
    "                    angle_y_col: 'angle_y'\n",
    "                })\n",
    "            \n",
    "            # 提取文件名\n",
    "            self.df_angles['filename'] = self.df_angles['image_path'].apply(os.path.basename)\n",
    "            \n",
    "            print(f\"成功加载 {len(self.df_angles)} 条角度数据\")\n",
    "            print(f\"数据预览:\")\n",
    "            print(self.df_angles.head())\n",
    "            \n",
    "            return self.df_angles\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"加载角度数据失败: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def load_coordinate_data(self, csv_path=None, sep=',', filename_col='image_name',\n",
    "                           coord_x_col='coord_x', coord_y_col='coord_y'):\n",
    "        \"\"\"\n",
    "        加载坐标数据CSV\n",
    "        \n",
    "        参数:\n",
    "            csv_path: CSV文件路径\n",
    "            sep: 分隔符，默认为逗号\n",
    "            filename_col: 文件名列名\n",
    "            coord_x_col: X坐标列名\n",
    "            coord_y_col: Y坐标列名\n",
    "        \"\"\"\n",
    "        if csv_path is None:\n",
    "            csv_path = self.coord_csv_path\n",
    "            \n",
    "        print(f\"正在加载坐标数据: {csv_path}\")\n",
    "        \n",
    "        try:\n",
    "            self.df_coords = pd.read_csv(csv_path, sep=sep)\n",
    "            print(f\"坐标数据列: {list(self.df_coords.columns)}\")\n",
    "            \n",
    "            # 重命名列以便统一处理\n",
    "            if filename_col in self.df_coords.columns:\n",
    "                self.df_coords = self.df_coords.rename(columns={\n",
    "                    filename_col: 'filename',\n",
    "                    coord_x_col: 'coord_x',\n",
    "                    coord_y_col: 'coord_y'\n",
    "                })\n",
    "            \n",
    "            print(f\"成功加载 {len(self.df_coords)} 条坐标数据\")\n",
    "            print(f\"数据预览:\")\n",
    "            print(self.df_coords.head())\n",
    "            \n",
    "            return self.df_coords\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"加载坐标数据失败: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def match_data(self, how='inner'):\n",
    "        \"\"\"\n",
    "        匹配角度和坐标数据\n",
    "        \n",
    "        参数:\n",
    "            how: 合并方式，'inner'（内连接，默认）、'outer'（外连接）、'left'（左连接）、'right'（右连接）\n",
    "        \"\"\"\n",
    "        if self.df_angles is None or self.df_coords is None:\n",
    "            print(\"请先加载角度和坐标数据\")\n",
    "            return None\n",
    "        \n",
    "        print(\"\\n开始匹配数据...\")\n",
    "        \n",
    "        # 合并数据\n",
    "        self.df_merged = pd.merge(\n",
    "            self.df_angles[['filename', 'angle_x', 'angle_y']],\n",
    "            self.df_coords[['filename', 'coord_x', 'coord_y']],\n",
    "            on='filename',\n",
    "            how=how\n",
    "        )\n",
    "        \n",
    "        # 统计匹配结果\n",
    "        total_angles = len(self.df_angles)\n",
    "        total_coords = len(self.df_coords)\n",
    "        matched = len(self.df_merged)\n",
    "        \n",
    "        print(f\"匹配完成:\")\n",
    "        print(f\"  - 角度数据总数: {total_angles}\")\n",
    "        print(f\"  - 坐标数据总数: {total_coords}\")\n",
    "        print(f\"  - 成功匹配: {matched}\")\n",
    "        print(f\"  - 匹配率: {matched/min(total_angles, total_coords)*100:.2f}%\")\n",
    "        \n",
    "        if how == 'inner':\n",
    "            # 对于内连接，检查未匹配的数据\n",
    "            unmatched_angles = self.df_angles[~self.df_angles['filename'].isin(self.df_merged['filename'])]\n",
    "            unmatched_coords = self.df_coords[~self.df_coords['filename'].isin(self.df_merged['filename'])]\n",
    "            \n",
    "            if len(unmatched_angles) > 0:\n",
    "                print(f\"\\n未匹配的角度数据 ({len(unmatched_angles)} 条):\")\n",
    "                print(unmatched_angles[['filename', 'angle_x', 'angle_y']].head())\n",
    "                \n",
    "            if len(unmatched_coords) > 0:\n",
    "                print(f\"\\n未匹配的坐标数据 ({len(unmatched_coords)} 条):\")\n",
    "                print(unmatched_coords[['filename', 'coord_x', 'coord_y']].head())\n",
    "        \n",
    "        # 提取数组\n",
    "        self.eye_points = self.df_merged[['coord_x', 'coord_y']].values.astype(np.float32)\n",
    "        self.screen_angles = self.df_merged[['angle_x', 'angle_y']].values.astype(np.float32)\n",
    "        angles_rad = np.radians(self.screen_angles)  # 转换为弧度\n",
    "        screen_x = np.tan(angles_rad[:,1])\n",
    "        screen_y = np.tan(angles_rad[:,0]) \n",
    "        self.screen_points = np.column_stack((screen_x, screen_y))\n",
    "\n",
    "\n",
    "        self.filenames = self.df_merged['filename'].values\n",
    "        \n",
    "        print(f\"\\n提取的数据形状:\")\n",
    "        print(f\"  eye_points: {self.eye_points.shape}\")\n",
    "        print(f\"  screen_points: {self.screen_points.shape}\")\n",
    "        \n",
    "        return self.df_merged\n",
    "    \n",
    "    def check_data_quality(self):\n",
    "        \"\"\"检查数据质量\"\"\"\n",
    "        if self.df_merged is None:\n",
    "            print(\"请先匹配数据\")\n",
    "            return\n",
    "        \n",
    "        print(\"\\n数据质量检查:\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # 1. 检查NaN值\n",
    "        nan_angles = self.df_merged[['angle_x', 'angle_y']].isna().sum().sum()\n",
    "        nan_coords = self.df_merged[['coord_x', 'coord_y']].isna().sum().sum()\n",
    "        \n",
    "        print(f\"1. NaN值统计:\")\n",
    "        print(f\"   角度数据NaN值: {nan_angles}\")\n",
    "        print(f\"   坐标数据NaN值: {nan_coords}\")\n",
    "        \n",
    "        # 2. 检查数据范围\n",
    "        print(f\"\\n2. 数据范围:\")\n",
    "        print(f\"   角度X范围: [{self.df_merged['angle_x'].min():.4f}, {self.df_merged['angle_x'].max():.4f}]\")\n",
    "        print(f\"   角度Y范围: [{self.df_merged['angle_y'].min():.4f}, {self.df_merged['angle_y'].max():.4f}]\")\n",
    "        print(f\"   坐标X范围: [{self.df_merged['coord_x'].min():.2f}, {self.df_merged['coord_x'].max():.2f}]\")\n",
    "        print(f\"   坐标Y范围: [{self.df_merged['coord_y'].min():.2f}, {self.df_merged['coord_y'].max():.2f}]\")\n",
    "        \n",
    "        # 3. 检查数据统计信息\n",
    "        print(f\"\\n3. 数据统计信息:\")\n",
    "        print(\"   角度数据:\")\n",
    "        print(self.df_merged[['angle_x', 'angle_y']].describe())\n",
    "        print(\"\\n   坐标数据:\")\n",
    "        print(self.df_merged[['coord_x', 'coord_y']].describe())\n",
    "        \n",
    "        # 4. 检查异常值（使用IQR方法）\n",
    "        def count_outliers(series):\n",
    "            Q1 = series.quantile(0.25)\n",
    "            Q3 = series.quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            outliers = (series < lower_bound) | (series > upper_bound)\n",
    "            return outliers.sum()\n",
    "        \n",
    "        outliers_angle_x = count_outliers(self.df_merged['angle_x'])\n",
    "        outliers_angle_y = count_outliers(self.df_merged['angle_y'])\n",
    "        outliers_coord_x = count_outliers(self.df_merged['coord_x'])\n",
    "        outliers_coord_y = count_outliers(self.df_merged['coord_y'])\n",
    "        \n",
    "        print(f\"\\n4. 异常值统计 (IQR方法):\")\n",
    "        print(f\"   角度X异常值: {outliers_angle_x} ({outliers_angle_x/len(self.df_merged)*100:.2f}%)\")\n",
    "        print(f\"   角度Y异常值: {outliers_angle_y} ({outliers_angle_y/len(self.df_merged)*100:.2f}%)\")\n",
    "        print(f\"   坐标X异常值: {outliers_coord_x} ({outliers_coord_x/len(self.df_merged)*100:.2f}%)\")\n",
    "        print(f\"   坐标Y异常值: {outliers_coord_y} ({outliers_coord_y/len(self.df_merged)*100:.2f}%)\")\n",
    "        \n",
    "        return {\n",
    "            'has_nan': nan_angles + nan_coords > 0,\n",
    "            'outliers': {\n",
    "                'angle_x': outliers_angle_x,\n",
    "                'angle_y': outliers_angle_y,\n",
    "                'coord_x': outliers_coord_x,\n",
    "                'coord_y': outliers_coord_y\n",
    "            }\n",
    "        }\n",
    "    \n",
    "\n",
    "\n",
    "    def split_by_filenames(self, train_filenames):\n",
    "    \n",
    "        if self.df_merged is None:\n",
    "            print(\"请先匹配数据\")\n",
    "            return None\n",
    "    \n",
    "    # 确保train_filenames是列表类型\n",
    "        if isinstance(train_filenames, str):\n",
    "            train_filenames = [train_filenames]\n",
    "    \n",
    "        print(f\"根据指定的 {len(train_filenames)} 个文件名分割数据...\")\n",
    "    \n",
    "    # 创建训练集掩码\n",
    "        train_mask = self.df_merged['filename'].isin(train_filenames)\n",
    "    \n",
    "    # 提取训练集\n",
    "        train_df = self.df_merged[train_mask]\n",
    "        eye_train = train_df[['coord_x', 'coord_y']].values.astype(np.float32)\n",
    "    \n",
    "    # 提取对应的screen_points（注意保持转换一致性）\n",
    "        screen_angles_train = train_df[['angle_x', 'angle_y']].values.astype(np.float32)\n",
    "        angles_rad_train = np.radians(screen_angles_train)\n",
    "        screen_x_train = np.tan(angles_rad_train[:, 1])\n",
    "        screen_y_train = np.tan(angles_rad_train[:, 0])\n",
    "        screen_train = np.column_stack((screen_x_train, screen_y_train))\n",
    "    \n",
    "    # 提取测试集（剩余数据）\n",
    "        test_df = self.df_merged[~train_mask]\n",
    "        eye_test = test_df[['coord_x', 'coord_y']].values.astype(np.float32)\n",
    "    \n",
    "        screen_angles_test = test_df[['angle_x', 'angle_y']].values.astype(np.float32)\n",
    "        angles_rad_test = np.radians(screen_angles_test)\n",
    "        screen_x_test = np.tan(angles_rad_test[:, 1])\n",
    "        screen_y_test = np.tan(angles_rad_test[:, 0])\n",
    "        screen_test = np.column_stack((screen_x_test, screen_y_test))\n",
    "    \n",
    "        print(f\"分割完成:\")\n",
    "        print(f\"  训练集大小: {len(train_df)} (基于 {len(train_filenames)} 个指定文件名)\")\n",
    "        print(f\"  测试集大小: {len(test_df)}\")\n",
    "        print(f\"  总数据量: {len(self.df_merged)}\")\n",
    "    \n",
    "    # 打印训练集使用的具体文件名\n",
    "        print(f\"  训练集文件名示例: {train_filenames[:9] if len(train_filenames) > 9 else train_filenames}\")\n",
    "    \n",
    "        return eye_train, eye_test, screen_train, screen_test\n",
    "    def visualize_data(self, save_fig=False, output_dir='output'):\n",
    "        \"\"\"可视化数据分布\"\"\"\n",
    "        if self.df_merged is None:\n",
    "            print(\"请先匹配数据\")\n",
    "            return\n",
    "        \n",
    "        # 创建输出目录\n",
    "        if save_fig and not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        \n",
    "        # 创建2x2的子图\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "        fig.suptitle('视线数据分布可视化', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # 1. 坐标分布散点图\n",
    "        axes[0, 0].scatter(self.eye_points[:, 0], self.eye_points[:, 1], \n",
    "                          alpha=0.6, s=20, c='blue', edgecolors='white', linewidth=0.5)\n",
    "        axes[0, 0].set_xlabel('X Coordinate', fontsize=12)\n",
    "        axes[0, 0].set_ylabel('Y Coordinate', fontsize=12)\n",
    "        axes[0, 0].set_title('Eye Points Distribution (Image Coordinates)', fontsize=13)\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        axes[0, 0].set_aspect('equal', adjustable='box')\n",
    "        \n",
    "        # 2. 角度分布散点图\n",
    "        axes[0, 1].scatter(self.screen_points[:, 0], self.screen_points[:, 1], \n",
    "                          alpha=0.6, s=20, c='red', edgecolors='white', linewidth=0.5)\n",
    "        axes[0, 1].set_xlabel('X Angle', fontsize=12)\n",
    "        axes[0, 1].set_ylabel('Y Angle', fontsize=12)\n",
    "        axes[0, 1].set_title('Gaze Points Distribution (Screen Angles)', fontsize=13)\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        axes[0, 1].set_aspect('equal', adjustable='box')\n",
    "        \n",
    "        # 3. 坐标分布直方图\n",
    "        axes[1, 0].hist2d(self.eye_points[:, 0], self.eye_points[:, 1], \n",
    "                         bins=30, cmap='Blues')\n",
    "        axes[1, 0].set_xlabel('X Coordinate', fontsize=12)\n",
    "        axes[1, 0].set_ylabel('Y Coordinate', fontsize=12)\n",
    "        axes[1, 0].set_title('Eye Points Density Distribution', fontsize=13)\n",
    "        \n",
    "        # 4. 角度分布直方图\n",
    "        axes[1, 1].hist2d(self.screen_points[:, 0], self.screen_points[:, 1], \n",
    "                         bins=30, cmap='Reds')\n",
    "        axes[1, 1].set_xlabel('X Angle', fontsize=12)\n",
    "        axes[1, 1].set_ylabel('Y Angle', fontsize=12)\n",
    "        axes[1, 1].set_title('Gaze Points Density Distribution', fontsize=13)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_fig:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            fig_path = os.path.join(output_dir, f'data_distribution_{timestamp}.png')\n",
    "            plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "            print(f\"可视化图像已保存到: {fig_path}\")\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        # 相关系数矩阵\n",
    "        print(\"\\n相关系数矩阵:\")\n",
    "        corr_matrix = self.df_merged[['coord_x', 'coord_y', 'angle_x', 'angle_y']].corr()\n",
    "        print(corr_matrix)\n",
    "        \n",
    "        # 绘制相关系数热图\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "                   square=True, fmt='.3f', linewidths=1)\n",
    "        plt.title('相关系数矩阵热图', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_fig:\n",
    "            heatmap_path = os.path.join(output_dir, f'correlation_heatmap_{timestamp}.png')\n",
    "            plt.savefig(heatmap_path, dpi=300, bbox_inches='tight')\n",
    "            print(f\"相关系数热图已保存到: {heatmap_path}\")\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "    def save_matched_data(self, output_path='matched_gaze_data.csv'):\n",
    "        \"\"\"保存匹配后的数据\"\"\"\n",
    "        if self.df_merged is None:\n",
    "            print(\"请先匹配数据\")\n",
    "            return\n",
    "        \n",
    "        # 确保目录存在\n",
    "        output_dir = os.path.dirname(output_path)\n",
    "        if output_dir and not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        \n",
    "        self.df_merged.to_csv(output_path, index=False)\n",
    "        print(f\"匹配数据已保存到: {output_path}\")\n",
    "        \n",
    "        return output_path\n",
    "    \n",
    "    def split_data(self, test_size=0.2, random_state=42):\n",
    "        \"\"\"分割数据集为训练集和测试集\"\"\"\n",
    "        if self.eye_points is None or self.screen_points is None:\n",
    "            print(\"请先匹配数据\")\n",
    "            return None\n",
    "        \n",
    "        eye_train, eye_test, screen_train, screen_test = train_test_split(\n",
    "            self.eye_points, self.screen_points, \n",
    "            test_size=test_size, \n",
    "            random_state=random_state\n",
    "        )\n",
    "        \n",
    "        print(f\"数据分割完成:\")\n",
    "        print(f\"  训练集大小: {eye_train.shape[0]}\")\n",
    "        print(f\"  测试集大小: {eye_test.shape[0]}\")\n",
    "        \n",
    "        return eye_train, eye_test, screen_train, screen_test\n",
    "# 假设你想使用以下5个特定文件作为训练集\n",
    "specified_train_files = [\n",
    "    'frame_1.png', \n",
    "    'frame_16.png', \n",
    "    'frame_31.png', \n",
    "    'frame_466.png', \n",
    "    'frame_481.png',\n",
    "    'frame_496.png', \n",
    "    'frame_930.png', \n",
    "    'frame_946.png', \n",
    "    'frame_961.png'\n",
    "]\n",
    "\n",
    "# 调用新方法\n",
    "\n",
    "angle_csv=r'C:\\Users\\86155\\Desktop\\20250709\\twolayer3\\coordinate_mapping.csv'\n",
    "cord_csv=r'C:\\Users\\86155\\Desktop\\20250709\\twolayer3\\segmentation_results_data\\class2_centroids.csv'\n",
    "angle_data = pd.read_csv(angle_csv)\n",
    "coord_data = pd.read_csv(cord_csv)\n",
    "\n",
    "# 创建处理器并加载数据\n",
    "processor = GazeDataProcessor(angle_data, coord_data)\n",
    "processor.match_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3fe4f2",
   "metadata": {},
   "source": [
    "建立基于多项式回归的视线追踪模型，将瞳孔中心坐标映射到屏幕注视点坐标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6852c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GazePolynomialModel:\n",
    "    \"\"\"视线多项式回归模型类\"\"\"\n",
    "    \n",
    "    def __init__(self, degree=2, alpha=0.0):\n",
    "        \"\"\"\n",
    "        初始化多项式回归模型\n",
    "        \n",
    "        参数:\n",
    "            degree: 多项式阶数，默认为2\n",
    "            alpha: 正则化参数，默认为0（线性回归），>0为岭回归\n",
    "        \"\"\"\n",
    "        self.degree = degree\n",
    "        self.alpha = alpha\n",
    "        self.poly = PolynomialFeatures(degree=degree, include_bias=True)\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "        # if alpha > 0:\n",
    "        #     self.model_x = Ridge(alpha=alpha, random_state=42)\n",
    "        #     self.model_y = Ridge(alpha=alpha, random_state=42)\n",
    "        # else:\n",
    "        self.model_x = LinearRegression()\n",
    "        self.model_y = LinearRegression()\n",
    "        \n",
    "        self.coefficients_x = None\n",
    "        self.coefficients_y = None\n",
    "        self.intercept_x = None\n",
    "        self.intercept_y = None\n",
    "        self.poly_feature_names = None\n",
    "        self.scaler_mean = None\n",
    "        self.scaler_scale = None\n",
    "\n",
    "        self.is_fitted = False\n",
    "        \n",
    "    def fit(self, eye_points, screen_points):\n",
    "        \"\"\"训练模型\"\"\"\n",
    "        print(f\"训练多项式回归模型 (degree={self.degree}, alpha={self.alpha})...\")\n",
    "        \n",
    "        # 生成多项式特征\n",
    "        X_poly = self.poly.fit_transform(eye_points)\n",
    "        self.poly_feature_names = self.poly.get_feature_names_out(['eye_x', 'eye_y'])\n",
    "        # 标准化特征\n",
    "        X_scaled = self.scaler.fit_transform(X_poly)\n",
    "        self.scaler_mean = self.scaler.mean_\n",
    "        self.scaler_scale = self.scaler.scale_\n",
    "\n",
    "        # 训练X方向模型\n",
    "        self.model_x.fit(X_scaled, screen_points[:, 0])\n",
    "        self.coefficients_x = self.model_x.coef_\n",
    "        self.intercept_x = self.model_x.intercept_\n",
    "\n",
    "        # 训练Y方向模型\n",
    "        self.model_y.fit(X_scaled, screen_points[:, 1])\n",
    "        self.coefficients_y = self.model_y.coef_\n",
    "        self.intercept_y = self.model_y.intercept_\n",
    "        self.is_fitted = True\n",
    "        print(\"模型训练完成\")\n",
    "        self._print_coefficients()\n",
    "        return self\n",
    "    \n",
    "    def _print_coefficients(self):\n",
    "        \"\"\"打印模型系数\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"模型系数信息:\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        print(f\"多项式特征 (degree={self.degree}):\")\n",
    "        for i, name in enumerate(self.poly_feature_names):\n",
    "            print(f\"  {i}: {name}\")\n",
    "        \n",
    "        print(f\"\\nX方向模型系数 (共{len(self.coefficients_x)}个):\")\n",
    "        for i, (name, coeff) in enumerate(zip(self.poly_feature_names, self.coefficients_x)):\n",
    "            print(f\"  {name}: {coeff:.6f}\")\n",
    "        print(f\"  截距: {self.intercept_x:.6f}\")\n",
    "        \n",
    "        print(f\"\\nY方向模型系数 (共{len(self.coefficients_y)}个):\")\n",
    "        for i, (name, coeff) in enumerate(zip(self.poly_feature_names, self.coefficients_y)):\n",
    "            print(f\"  {name}: {coeff:.6f}\")\n",
    "        print(f\"  截距: {self.intercept_y:.6f}\")\n",
    "        \n",
    "        print(f\"\\n标准化器参数:\")\n",
    "        print(f\"  均值 (mean): {self.scaler_mean}\")\n",
    "        print(f\"  标准差 (scale): {self.scaler_scale}\")\n",
    "        print(\"=\"*60)\n",
    "    \n",
    "    def get_coefficients(self):\n",
    "        \"\"\"获取模型的所有系数\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"模型尚未训练，请先调用fit方法\")\n",
    "        \n",
    "        return {\n",
    "            'degree': self.degree,\n",
    "            'alpha': self.alpha,\n",
    "            'poly_feature_names': self.poly_feature_names,\n",
    "            'coefficients_x': self.coefficients_x,\n",
    "            'coefficients_y': self.coefficients_y,\n",
    "            'intercept_x': self.intercept_x,\n",
    "            'intercept_y': self.intercept_y,\n",
    "            'scaler_mean': self.scaler_mean,\n",
    "            'scaler_scale': self.scaler_scale,\n",
    "            'model_x_coef': self.model_x.coef_,\n",
    "            'model_x_intercept': self.model_x.intercept_,\n",
    "            'model_y_coef': self.model_y.coef_,\n",
    "            'model_y_intercept': self.model_y.intercept_\n",
    "        }\n",
    "    \n",
    "    def save_coefficients(self, filepath='model_coefficients.pkl'):\n",
    "        \"\"\"保存模型系数到文件\"\"\"\n",
    "        import pickle\n",
    "        \n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"模型尚未训练，无法保存系数\")\n",
    "        \n",
    "        # 收集所有需要保存的数据\n",
    "        model_data = {\n",
    "            'degree': self.degree,\n",
    "            'alpha': self.alpha,\n",
    "            'poly_feature_names': self.poly_feature_names,\n",
    "            'coefficients_x': self.coefficients_x,\n",
    "            'coefficients_y': self.coefficients_y,\n",
    "            'intercept_x': self.intercept_x,\n",
    "            'intercept_y': self.intercept_y,\n",
    "            'scaler_mean': self.scaler_mean,\n",
    "            'scaler_scale': self.scaler_scale,\n",
    "            'is_fitted': self.is_fitted\n",
    "        }\n",
    "        \n",
    "        # 保存到文件\n",
    "        with open(filepath, 'wb') as f:\n",
    "            pickle.dump(model_data, f)\n",
    "        \n",
    "        print(f\"模型系数已保存到: {filepath}\")\n",
    "        \n",
    "        # 同时保存为文本文件便于查看\n",
    "        txt_filepath = filepath.replace('.pkl', '.txt')\n",
    "        self.save_coefficients_txt(txt_filepath)\n",
    "        \n",
    "        return filepath\n",
    "    \n",
    "    def save_coefficients_txt(self, filepath='model_coefficients.txt'):\n",
    "        \"\"\"保存模型系数到文本文件\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"模型尚未训练，无法保存系数\")\n",
    "        \n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"=\"*60 + \"\\n\")\n",
    "            f.write(\"注视点映射模型系数\\n\")\n",
    "            f.write(\"=\"*60 + \"\\n\\n\")\n",
    "            \n",
    "            f.write(f\"模型配置:\\n\")\n",
    "            f.write(f\"  多项式阶数 (degree): {self.degree}\\n\")\n",
    "            f.write(f\"  正则化参数 (alpha): {self.alpha}\\n\")\n",
    "            f.write(f\"  是否已训练: {self.is_fitted}\\n\\n\")\n",
    "            \n",
    "            f.write(\"多项式特征:\\n\")\n",
    "            for i, name in enumerate(self.poly_feature_names):\n",
    "                f.write(f\"  {i}: {name}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "            \n",
    "            f.write(\"标准化器参数:\\n\")\n",
    "            f.write(f\"  均值 (mean): {self.scaler_mean}\\n\")\n",
    "            f.write(f\"  标准差 (scale): {self.scaler_scale}\\n\\n\")\n",
    "            \n",
    "            f.write(\"X方向模型系数:\\n\")\n",
    "            f.write(f\"  截距: {self.intercept_x:.10f}\\n\")\n",
    "            for i, (name, coeff) in enumerate(zip(self.poly_feature_names, self.coefficients_x)):\n",
    "                f.write(f\"  {name}: {coeff:.10f}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "            \n",
    "            f.write(\"Y方向模型系数:\\n\")\n",
    "            f.write(f\"  截距: {self.intercept_y:.10f}\\n\")\n",
    "            for i, (name, coeff) in enumerate(zip(self.poly_feature_names, self.coefficients_y)):\n",
    "                f.write(f\"  {name}: {coeff:.10f}\\n\")\n",
    "        \n",
    "        print(f\"模型系数(文本)已保存到: {filepath}\")\n",
    "        return filepath\n",
    "    \n",
    "    def save_full_model(self, filepath='gaze_model_full.pkl'):\n",
    "        \"\"\"保存完整模型对象（包括所有子模型）\"\"\"\n",
    "        import pickle\n",
    "        \n",
    "        model_data = {\n",
    "            'model_object': self,  # 保存整个对象\n",
    "            'metadata': {\n",
    "                'degree': self.degree,\n",
    "                'alpha': self.alpha,\n",
    "                'is_fitted': self.is_fitted\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        with open(filepath, 'wb') as f:\n",
    "            pickle.dump(model_data, f)\n",
    "        \n",
    "        print(f\"完整模型已保存到: {filepath}\")\n",
    "        return filepath\n",
    "    \n",
    "    def predict(self, eye_points):\n",
    "        \"\"\"预测注视点\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"模型尚未训练，请先调用fit方法\")\n",
    "        \n",
    "        # 生成多项式特征\n",
    "        X_poly = self.poly.transform(eye_points)\n",
    "        \n",
    "        # 标准化特征\n",
    "        X_scaled = self.scaler.transform(X_poly)\n",
    "        \n",
    "        # 预测\n",
    "        pred_x = self.model_x.predict(X_scaled)\n",
    "        pred_y = self.model_y.predict(X_scaled)\n",
    "        \n",
    "        return np.column_stack([pred_x, pred_y])\n",
    "    \n",
    "    def evaluate(self, eye_points, screen_points, verbose=True):\n",
    "        \"\"\"评估模型性能\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"模型尚未训练，请先调用fit方法\")\n",
    "        \n",
    "        # 预测\n",
    "        predictions = self.predict(eye_points)\n",
    "        \n",
    "        # 计算各种指标\n",
    "        mse_x = mean_squared_error(screen_points[:, 0], predictions[:, 0])\n",
    "        mse_y = mean_squared_error(screen_points[:, 1], predictions[:, 1])\n",
    "        mse_total = mean_squared_error(screen_points.flatten(), predictions.flatten())\n",
    "        \n",
    "        mae_x = mean_absolute_error(screen_points[:, 0], predictions[:, 0])\n",
    "        mae_y = mean_absolute_error(screen_points[:, 1], predictions[:, 1])\n",
    "        mae_total = mean_absolute_error(screen_points.flatten(), predictions.flatten())\n",
    "        \n",
    "        rmse_x = np.sqrt(mse_x)\n",
    "        rmse_y = np.sqrt(mse_y)\n",
    "        rmse_total = np.sqrt(mse_total)\n",
    "        \n",
    "        # 计算相关系数\n",
    "        corr_x, p_x = pearsonr(screen_points[:, 0], predictions[:, 0])\n",
    "        corr_y, p_y = pearsonr(screen_points[:, 1], predictions[:, 1])\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"\\n模型性能评估:\")\n",
    "            print(\"=\" * 60)\n",
    "            print(f\"{'指标':<15} {'X方向':<15} {'Y方向':<15} {'总体':<15}\")\n",
    "            print(\"-\" * 60)\n",
    "            print(f\"{'MSE':<15} {mse_x:<15.6f} {mse_y:<15.6f} {mse_total:<15.6f}\")\n",
    "            print(f\"{'RMSE':<15} {rmse_x:<15.6f} {rmse_y:<15.6f} {rmse_total:<15.6f}\")\n",
    "            print(f\"{'MAE':<15} {mae_x:<15.6f} {mae_y:<15.6f} {mae_total:<15.6f}\")\n",
    "            print(f\"{'相关系数':<15} {corr_x:<15.6f} {corr_y:<15.6f} {'-':<15}\")\n",
    "            print(f\"{'P值':<15} {p_x:<15.6f} {p_y:<15.6f} {'-':<15}\")\n",
    "        \n",
    "        return {\n",
    "            'mse_x': mse_x, 'mse_y': mse_y, 'mse_total': mse_total,\n",
    "            'rmse_x': rmse_x, 'rmse_y': rmse_y, 'rmse_total': rmse_total,\n",
    "            'mae_x': mae_x, 'mae_y': mae_y, 'mae_total': mae_total,\n",
    "            'corr_x': corr_x, 'corr_y': corr_y,\n",
    "            'p_x': p_x, 'p_y': p_y\n",
    "        }\n",
    "    \n",
    "    def cross_validate(self, eye_points, screen_points, cv=5, verbose=True):\n",
    "        \"\"\"交叉验证\"\"\"\n",
    "        # 生成多项式特征\n",
    "        X_poly = self.poly.fit_transform(eye_points)\n",
    "        X_scaled = self.scaler.fit_transform(X_poly)\n",
    "        \n",
    "        # 交叉验证X方向\n",
    "        cv_scores_x = cross_val_score(self.model_x, X_scaled, screen_points[:, 0], \n",
    "                                     cv=cv, scoring='neg_mean_squared_error')\n",
    "        mse_scores_x = -cv_scores_x\n",
    "        rmse_scores_x = np.sqrt(mse_scores_x)\n",
    "        \n",
    "        # 交叉验证Y方向\n",
    "        cv_scores_y = cross_val_score(self.model_y, X_scaled, screen_points[:, 1], \n",
    "                                     cv=cv, scoring='neg_mean_squared_error')\n",
    "        mse_scores_y = -cv_scores_y\n",
    "        rmse_scores_y = np.sqrt(mse_scores_y)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\n{self.degree}阶多项式模型交叉验证结果 (cv={cv}):\")\n",
    "            print(\"=\" * 60)\n",
    "            print(f\"{'方向':<10} {'MSE均值':<15} {'MSE标准差':<15} {'RMSE均值':<15} {'RMSE标准差':<15}\")\n",
    "            print(\"-\" * 60)\n",
    "            print(f\"{'X方向':<10} {np.mean(mse_scores_x):<15.6f} {np.std(mse_scores_x):<15.6f} \"\n",
    "                  f\"{np.mean(rmse_scores_x):<15.6f} {np.std(rmse_scores_x):<15.6f}\")\n",
    "            print(f\"{'Y方向':<10} {np.mean(mse_scores_y):<15.6f} {np.std(mse_scores_y):<15.6f} \"\n",
    "                  f\"{np.mean(rmse_scores_y):<15.6f} {np.std(rmse_scores_y):<15.6f}\")\n",
    "        \n",
    "        return {\n",
    "            'mse_x_scores': mse_scores_x, 'mse_y_scores': mse_scores_y,\n",
    "            'rmse_x_scores': rmse_scores_x, 'rmse_y_scores': rmse_scores_y\n",
    "        }\n",
    "    \n",
    "    def find_best_degree(self, eye_points, screen_points, max_degree=5, cv=5, test_size=0.2):\n",
    "        \"\"\"寻找最佳多项式阶数\"\"\"\n",
    "        print(f\"寻找最佳多项式阶数 (1-{max_degree})...\")\n",
    "        \n",
    "        degrees = range(1, max_degree + 1)\n",
    "        results = []\n",
    "        \n",
    "        # 分割数据\n",
    "        eye_train, eye_test, screen_train, screen_test = train_test_split(\n",
    "            eye_points, screen_points, test_size=test_size, random_state=42\n",
    "        )\n",
    "        \n",
    "        for degree in degrees:\n",
    "            print(f\"  测试阶数 {degree}...\")\n",
    "            \n",
    "            # 创建模型\n",
    "            model = GazePolynomialModel(degree=degree, alpha=self.alpha)\n",
    "            \n",
    "            # 交叉验证\n",
    "            cv_results = model.cross_validate(eye_train, screen_train, cv=cv, verbose=False)\n",
    "            \n",
    "            # 训练模型\n",
    "            model.fit(eye_train, screen_train)\n",
    "            \n",
    "            # 在测试集上评估\n",
    "            test_results = model.evaluate(eye_test, screen_test, verbose=False)\n",
    "            \n",
    "            results.append({\n",
    "                'degree': degree,\n",
    "                'cv_rmse_x_mean': np.mean(cv_results['rmse_x_scores']),\n",
    "                'cv_rmse_y_mean': np.mean(cv_results['rmse_y_scores']),\n",
    "                'test_rmse_total': test_results['rmse_total'],\n",
    "                'test_corr_x': test_results['corr_x'],\n",
    "                'test_corr_y': test_results['corr_y']\n",
    "            })\n",
    "        \n",
    "        # 转换为DataFrame\n",
    "        results_df = pd.DataFrame(results)\n",
    "        \n",
    "        # 找到最佳阶数（基于测试集总RMSE）\n",
    "        best_idx = results_df['test_rmse_total'].idxmin()\n",
    "        best_degree = results_df.loc[best_idx, 'degree']\n",
    "        best_rmse = results_df.loc[best_idx, 'test_rmse_total']\n",
    "        \n",
    "        print(f\"\\n最佳多项式阶数: {best_degree} (测试集RMSE={best_rmse:.6f})\")\n",
    "        print(\"\\n各阶数性能对比:\")\n",
    "        print(results_df.to_string(index=False))\n",
    "        \n",
    "        # 可视化结果\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        \n",
    "        # RMSE随阶数变化\n",
    "        axes[0].plot(results_df['degree'], results_df['cv_rmse_x_mean'], 'o-', label='X方向交叉验证RMSE')\n",
    "        axes[0].plot(results_df['degree'], results_df['cv_rmse_y_mean'], 's-', label='Y方向交叉验证RMSE')\n",
    "        axes[0].plot(results_df['degree'], results_df['test_rmse_total'], '^-', label='测试集总RMSE')\n",
    "        axes[0].axvline(x=best_degree, color='r', linestyle='--', alpha=0.7, label=f'最佳阶数={best_degree}')\n",
    "        axes[0].set_xlabel('多项式阶数')\n",
    "        axes[0].set_ylabel('RMSE')\n",
    "        axes[0].set_title('RMSE随多项式阶数变化')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 相关系数随阶数变化\n",
    "        axes[1].plot(results_df['degree'], results_df['test_corr_x'], 'o-', label='X方向相关系数')\n",
    "        axes[1].plot(results_df['degree'], results_df['test_corr_y'], 's-', label='Y方向相关系数')\n",
    "        axes[1].axvline(x=best_degree, color='r', linestyle='--', alpha=0.7, label=f'最佳阶数={best_degree}')\n",
    "        axes[1].set_xlabel('多项式阶数')\n",
    "        axes[1].set_ylabel('相关系数')\n",
    "        axes[1].set_title('相关系数随多项式阶数变化')\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return best_degree, results_df\n",
    "    \n",
    "    def visualize_predictions(self, eye_points, screen_points, sample_size=961):\n",
    "        \"\"\"可视化预测结果\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"模型尚未训练，请先调用fit方法\")\n",
    "        \n",
    "        # 预测\n",
    "        predictions = self.predict(eye_points)\n",
    "        \n",
    "        # 随机选择一部分样本\n",
    "        if len(eye_points) > sample_size:\n",
    "            indices = np.random.choice(len(eye_points), sample_size, replace=False)\n",
    "            eye_sample = eye_points[indices]\n",
    "            screen_sample = screen_points[indices]\n",
    "            pred_sample = predictions[indices]\n",
    "        else:\n",
    "            eye_sample = eye_points\n",
    "            screen_sample = screen_points\n",
    "            pred_sample = predictions\n",
    "        \n",
    "        # 创建可视化\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "        \n",
    "        # 预测 vs 真实值散点图\n",
    "        axes[0].scatter(screen_sample[:, 0], pred_sample[:, 0], alpha=0.6, label='X方向')\n",
    "        axes[0].scatter(screen_sample[:, 1], pred_sample[:, 1], alpha=0.6, label='Y方向')\n",
    "        \n",
    "        # 添加对角线（完美预测线）\n",
    "        min_val = min(screen_sample.min(), pred_sample.min())\n",
    "        max_val = max(screen_sample.max(), pred_sample.max())\n",
    "        axes[0].plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.7, label='完美预测')\n",
    "        \n",
    "        axes[0].set_xlabel('真实值')\n",
    "        axes[0].set_ylabel('预测值')\n",
    "        axes[0].set_title(f'预测值 vs 真实值 (多项式阶数={self.degree})')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        axes[0].set_aspect('equal', adjustable='box')\n",
    "        \n",
    "        # 预测误差分布\n",
    "        errors_x = pred_sample[:, 0] - screen_sample[:, 0]\n",
    "        errors_y = pred_sample[:, 1] - screen_sample[:, 1]\n",
    "        \n",
    "        axes[1].hist(errors_x, bins=20, alpha=0.7, label=f'X方向 (MAE={np.mean(np.abs(errors_x)):.4f})')\n",
    "        axes[1].hist(errors_y, bins=20, alpha=0.7, label=f'Y方向 (MAE={np.mean(np.abs(errors_y)):.4f})')\n",
    "        axes[1].axvline(x=0, color='r', linestyle='--', alpha=0.7)\n",
    "        axes[1].set_xlabel('预测误差')\n",
    "        axes[1].set_ylabel('频数')\n",
    "        axes[1].set_title('预测误差分布')\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        sample_errors = pred_sample - screen_sample\n",
    "        sample_error_magnitudes = np.sqrt(sample_errors[:, 0]**2 + sample_errors[:, 1]**2)\n",
    "        \n",
    "        sample_df = pd.DataFrame({\n",
    "            'true_screen_x': screen_sample[:, 0],\n",
    "            'true_screen_y': screen_sample[:, 1],\n",
    "            'pred_screen_x': pred_sample[:, 0],\n",
    "            'pred_screen_y': pred_sample[:, 1],\n",
    "            'error_x': sample_errors[:, 0],\n",
    "            'error_y': sample_errors[:, 1],\n",
    "            'error_magnitude': sample_error_magnitudes,\n",
    "            'is_visualization_sample': True  # 标记这是可视化样本\n",
    "        })\n",
    "        \n",
    "        sample_data_path = 'output/visualization_sample_data3.csv'\n",
    "        sample_df.to_csv(sample_data_path, index=False, encoding='utf-8')\n",
    "        print(f\"可视化样本数据已保存到: {sample_data_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0b2542",
   "metadata": {},
   "source": [
    "整合之前定义的 GazeDataProcessor 和 GazePolynomialModel 类，执行从数据加载到模型训练的完整流程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44d4a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_demo():\n",
    "    \"\"\"主演示函数\"\"\"\n",
    "    print(\"=\" * 70)\n",
    "    print(\"视线数据匹配与多项式回归建模系统\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # 初始化数据处理器\n",
    "    processor = GazeDataProcessor()\n",
    "    \n",
    "    # 1. 加载数据（请替换为您的实际文件路径）\n",
    "    # 假设您的CSV文件格式：\n",
    "    # 角度数据CSV: image_path,angle_x,angle_y\n",
    "    # 坐标数据CSV: image_name,coord_x,coord_y\n",
    "    \n",
    "    # 示例文件路径\n",
    "    angle_csv = r\"C:\\Users\\86155\\Desktop\\20250709\\twolayer3\\coordinate_mapping.csv\"  # 请替换为您的实际文件路径\n",
    "    coord_csv = r\"C:\\Users\\86155\\Desktop\\20250709\\twolayer3\\segmentation_results_data\\class2_centroids.csv\"  # 请替换为您的实际文件路径\n",
    "    \n",
    "    # 加载数据\n",
    "    angles_df = processor.load_angle_data(angle_csv, sep=',')\n",
    "    coords_df = processor.load_coordinate_data(coord_csv, sep=',')\n",
    "    \n",
    "    if angles_df is None or coords_df is None:\n",
    "        print(\"数据加载失败，请检查文件路径和格式\")\n",
    "        return\n",
    "    \n",
    "    # 2. 匹配数据\n",
    "    df_merged = processor.match_data(how='inner')\n",
    "    \n",
    "    # 3. 检查数据质量\n",
    "    quality_info = processor.check_data_quality()\n",
    "    \n",
    "    # 4. 可视化数据\n",
    "    processor.visualize_data(save_fig=True, output_dir='output')\n",
    "    \n",
    "    # 5. 保存匹配数据\n",
    "    matched_file = processor.save_matched_data('output/matched_gaze_data.csv')\n",
    "    \n",
    "    # 6. 分割数据processor.split_by_filenames(specified_train_files)split_data(test_size=0.99, random_state=42)\n",
    "    eye_train, eye_test, screen_train, screen_test = processor.split_data(test_size=0.2, random_state=42)\n",
    "    \n",
    "    # 7. 寻找最佳多项式阶数\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"模型训练与优化\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    base_model = GazePolynomialModel(degree=2, alpha=0.0)\n",
    "    best_degree, degree_results = base_model.find_best_degree(\n",
    "        eye_train, screen_train, \n",
    "        max_degree=5, cv=5, test_size=0.2\n",
    "    )\n",
    "    \n",
    "    # 8. 使用最佳阶数训练模型\n",
    "    print(f\"\\n使用最佳阶数 {best_degree} 训练最终模型...\")\n",
    "    final_model = GazePolynomialModel(degree=best_degree, alpha=0.1)  # 添加一点正则化\n",
    "    \n",
    "    # 交叉验证\n",
    "    cv_results = final_model.cross_validate(eye_train, screen_train, cv=5)\n",
    "    \n",
    "    # 训练模型\n",
    "    final_model.fit(eye_train, screen_train)\n",
    "    \n",
    "    # 在测试集上评估\n",
    "    print(\"\\n测试集性能评估:\")\n",
    "    test_results = final_model.evaluate(eye_test, screen_test)\n",
    "    final_model.save_coefficients_txt('output/gaze_model_coefficients.txt')\n",
    "    # 9. 可视化预测结果\n",
    "    # final_model.visualize_predictions(eye_train, screen_train, sample_size=961)\n",
    "    final_model.visualize_predictions(processor.eye_points, processor.screen_points, sample_size=961)\n",
    "    # 10. 保存模型信息\n",
    "    model_info = {\n",
    "        'degree': best_degree,\n",
    "        'alpha': 0.1,\n",
    "        'train_samples': len(eye_train),\n",
    "        'test_samples': len(eye_test),\n",
    "        'test_rmse': test_results['rmse_total'],\n",
    "        'test_mae': test_results['mae_total'],\n",
    "        'test_corr_x': test_results['corr_x'],\n",
    "        'test_corr_y': test_results['corr_y']\n",
    "    }\n",
    "    \n",
    "    model_info_df = pd.DataFrame([model_info])\n",
    "    model_info_path = 'output/model_info.csv'\n",
    "    model_info_df.to_csv(model_info_path, index=False)\n",
    "    print(f\"\\n模型信息已保存到: {model_info_path}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"处理完成!\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    return processor, final_model, model_info\n",
    "\n",
    "\n",
    "def create_sample_data():\n",
    "    \"\"\"创建示例数据（如果实际数据不可用）\"\"\"\n",
    "    print(\"创建示例数据...\")\n",
    "    \n",
    "    # 创建输出目录\n",
    "    output_dir = 'sample_data'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # 生成100个样本\n",
    "    np.random.seed(42)\n",
    "    n_samples = 961\n",
    "    \n",
    "    # 生成文件名\n",
    "    filenames = [f'frame_{i}.png' for i in range(1, n_samples + 1)]\n",
    "    \n",
    "    # 生成坐标数据（模拟瞳孔中心位置）\n",
    "    coord_x = np.random.uniform(961, 500, n_samples)\n",
    "    coord_y = np.random.uniform(961, 400, n_samples)\n",
    "    \n",
    "    # 生成角度数据（模拟注视点方向）\n",
    "    # 假设简单的非线性关系\n",
    "    angle_x = 0.01 * coord_x + 0.002 * coord_y - 0.00001 * coord_x * coord_y + np.random.normal(0, 0.5, n_samples)\n",
    "    angle_y = 0.008 * coord_y + 0.001 * coord_x - 0.000005 * coord_x * coord_y + np.random.normal(0, 0.5, n_samples)\n",
    "    \n",
    "    # 添加路径前缀\n",
    "    paths = [f'C:/Users/username/dataset/train/data_ori/{filename}' for filename in filenames]\n",
    "    \n",
    "    # 创建角度数据DataFrame\n",
    "    angles_df = pd.DataFrame({\n",
    "        'image_path': paths,\n",
    "        'angle_x': angle_x,\n",
    "        'angle_y': angle_y\n",
    "    })\n",
    "    \n",
    "    # 创建坐标数据DataFrame\n",
    "    coords_df = pd.DataFrame({\n",
    "        'image_name': filenames,\n",
    "        'coord_x': coord_x,\n",
    "        'coord_y': coord_y\n",
    "    })\n",
    "    \n",
    "    # 保存CSV文件\n",
    "    angles_csv = os.path.join(output_dir, 'gaze_angles.csv')\n",
    "    coords_csv = os.path.join(output_dir, 'eye_coordinates.csv')\n",
    "    \n",
    "    angles_df.to_csv(angles_csv, index=False)\n",
    "    coords_df.to_csv(coords_csv, index=False)\n",
    "    \n",
    "    print(f\"示例角度数据已保存到: {angles_csv}\")\n",
    "    print(f\"示例坐标数据已保存到: {coords_csv}\")\n",
    "    print(f\"数据形状: 角度={angles_df.shape}, 坐标={coords_df.shape}\")\n",
    "    \n",
    "    return angles_csv, coords_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab5d99c",
   "metadata": {},
   "source": [
    "执行多项式拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b16fead",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # 运行主演示函数\n",
    "    processor, model, model_info = main_demo()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
